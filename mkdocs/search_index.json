{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\u00b6\n\n\nThis is the documentation for the \ncfgov-refresh\n project, a redesign of the \nwww.consumerfinance.gov\n website. It is organized thematically in order to create a central repository for all information pertaining to cfgov-refresh.\n\n\nDisclaimer\n\u00b6\n\n\nThis project is a work in progress.\n Nothing presented in this repo\u2014whether in the source code, issue tracker, or wiki\u2014is a final product unless it is marked as such or appears on \nwww.consumerfinance.gov\n. In-progress updates may appear on \nbeta.consumerfinance.gov\n.\n\n\nTechnology stack\n\u00b6\n\n\nThe standard technology stack for development of cfgov-refresh within the CFPB consists of the following base:\n\n\n\n\nmacOS\n\n\nHomebrew\n - package manager for installing system software on OSX\n\n\nPython and PIP (Python package manager)\n\n\nJinja templates\n for front-end rendering\n\n\nWagtail CMS\n for content administration\n\n\nDependencies, listed below\n\n\n\n\nDependencies\n\u00b6\n\n\n\n\nElasticsearch\n:\n  Used for full-text search capabilities and content indexing.\n\n\nNode\n and \nnpm (Node Package Manager)\n:\n  Used for downloading and managing front-end dependencies and assets.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "This is the documentation for the  cfgov-refresh  project, a redesign of the  www.consumerfinance.gov  website. It is organized thematically in order to create a central repository for all information pertaining to cfgov-refresh.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#disclaimer", 
            "text": "This project is a work in progress.  Nothing presented in this repo\u2014whether in the source code, issue tracker, or wiki\u2014is a final product unless it is marked as such or appears on  www.consumerfinance.gov . In-progress updates may appear on  beta.consumerfinance.gov .", 
            "title": "Disclaimer"
        }, 
        {
            "location": "/#technology-stack", 
            "text": "The standard technology stack for development of cfgov-refresh within the CFPB consists of the following base:   macOS  Homebrew  - package manager for installing system software on OSX  Python and PIP (Python package manager)  Jinja templates  for front-end rendering  Wagtail CMS  for content administration  Dependencies, listed below", 
            "title": "Technology stack"
        }, 
        {
            "location": "/#dependencies", 
            "text": "Elasticsearch :\n  Used for full-text search capabilities and content indexing.  Node  and  npm (Node Package Manager) :\n  Used for downloading and managing front-end dependencies and assets.", 
            "title": "Dependencies"
        }, 
        {
            "location": "/installation/", 
            "text": "Installation and configuration for cfgov-refresh\n\u00b6\n\n\nClone the repository\n\u00b6\n\n\nUsing the console, navigate to the root directory in which your projects\nlive and clone this project's repository:\n\n\ngit clone git@github.com:cfpb/cfgov-refresh.git\ncd cfgov-refresh\n\n\n\nYou may also wish to fork the repository on GitHub and clone the resultant\npersonal fork. This is advised if you are going to be doing development on\n\ncfgov-refresh\n and contributing to the project.\n\n\nThere are two ways to install cfgov-refresh:\n\n\n\n\nStand-alone installation\n\n\nDocker-compose installation\n\n\n\n\nStand-alone installation\n\u00b6\n\n\nThese instructions are somewhat specific to developing on macOS,\nbut if you're familiar with other Unix-based systems,\nit should be fairly easy to adapt them to your needs.\n\n\nInstall system-level requirements\n\u00b6\n\n\nvirtualenv \n virtualenvwrapper Python modules\n\u00b6\n\n\nInstall \nvirtualenv\n\nand \nvirtualenvwrapper\n\nto be able to create a local environment for your server:\n\n\npip install virtualenv virtualenvwrapper\n\n\n\nAutoenv module\n\u00b6\n\n\nThis project uses a large number of environment variables.\n\n\nTo automatically define environment variables and launch the virtualenv\nupon \ncd\ning to the project folder,\n\ninstall Autoenv\n.\nWe recommend using \nHomebrew\n:\n\n\nbrew install autoenv\n\n\n\nAfter installation, Homebrew will output instructions similar to:\n\n\nTo finish the installation, source activate.sh in your shell:\n  source /Users/[YOUR USERNAME]/homebrew/opt/autoenv/activate.sh\n\n\n\nRun that now for your initial setup.\nAny time you run the project you\u2019ll need to run that last line, so\nif you\u2019ll be working with the project consistently,\nwe suggest adding it to your Bash profile by running:\n\n\necho 'source /Users/[YOUR USERNAME]/homebrew/opt/autoenv/activate.sh' \n ~/.bash_profile\n\n\n\nIf you need to find this info again later, you can run:\n\n\nbrew info autoenv\n\n\n\n\n\nNote\n\n\nIf you use Zsh you\u2019ll need to use\n\nzsh-autoenv\n,\nbut we can\u2019t provide support for issues that may arise.\n\n\n\n\nFront-end dependencies\n\u00b6\n\n\nThe cfgov-refresh front end currently uses the following frameworks / tools:\n\n\n\n\nGulp\n: task management for pulling in assets,\n  linting and concatenating code, etc.\n\n\nLess\n: CSS pre-processor.\n\n\nCapital Framework\n:\n  User interface pattern-library produced by the CFPB.\n\n\n\n\n\n\nNote\n\n\nIf you\u2019re new to Capital Framework, we encourage you to\n\nstart here\n.\n\n\n\n\n\n\n\n\nInstall \nNode.js\n however you\u2019d like.\n   We recommend using \nnvm\n, though.\n\n\n\n\n\n\nInstall \nGulp\n:\n\n\n\n\n\n\nnpm install -g gulp\n\n\n\n\n\nNote\n\n\nThis project requires Node.js v8 or higher, and npm v5 or higher.\n\n\n\n\nWebfonts\n\u00b6\n\n\nThe site uses a proprietary licensed font, Avenir.\nIf you want to pull this from a content delivery network (CDN),\nyou can set the\n\n@use-font-cdn\n\nto \ntrue\n and rebuild the assets with \ngulp build\n.\nIf you want to install self-hosted fonts locally, you can place the font files\nin \nstatic.in/cfgov-fonts/fonts/\n and restart the local web server.\nIf you are a CFPB employee, you can perform this step with:\n\n\ncd static.in/ \n git clone https://[GHE]/CFGOV/cfgov-fonts/\n\nWhere \n[GHE]\n is our GitHub Enterprise URL.\n\n\nSet up your environment\n\u00b6\n\n\nThe Django app relies on environment variables defined in a \n.env\n file. If this\nis your first time setting up the project, copy \n.env_SAMPLE\n to \n.env\n and then\n\nsource\n that file:\n\n\ncp -a .env_SAMPLE .env\nsource .env\n\n\n\nEach time you start a new session for working on this project, you'll need to\nget those environment variables and get your virtualenv running again.\n\n\nIf you setup Autoenv earlier, this will happen for you automatically when you\n\ncd\n into the project directory.\n\n\nIf you prefer not to use Autoenv, just be sure to \nsource .env\n every time\nyou start a new session of work on the project.\n\n\nOptional (but recommended): use Postgres instead of SQLite\n\u00b6\n\n\nWe default to SQLite for the Django backend to make it easy to get started, but\nPostgres is our preferred database, and we recommend you consider installing it\nif you are comfortable doing this.\n\n\nIf you're on a Mac and use Homebrew, you can easily install Postgres:\n\n\nbrew install postgresql\n\n\n\nOnce it's installed, you can configure it to run as a service:\n\n\nbrew services start postgresql\n\n\n\nThen create the database and associated user:\n\n\ndropdb --if-exists cfgov \n dropuser --if-exists cfpb\ncreateuser cfpb \n createdb -O cfpb cfgov\n\n\n\nYou'll also need to update your \n.env\n file to comment out the line that\nspecifies SQLite as the db:\n\n\n# export DATABASE_URL=sqlite:///db.sqlite3\n\n\n\nAnd then uncomment the line that tells Django to use Postgres:\n\n\nexport DATABASE_URL=postgres://cfpb@localhost/cfgov\n\n\n\nRun the setup script\n\u00b6\n\n\nAt this point, your machine should have everything it needs to automate the\nrest of the setup process.\n\n\nIf you haven't cloned this repo yet, clone it to a local folder.\nBecause related projects will need to be installed as siblings to this project,\nwe recommend putting them all in their own folder, e.g., \n~/Projects/cf.gov\n.\n\n\nOnce cloned, from the project root (\n~/Projects/cf.gov/cfgov-refresh/\n),\nrun this command to complete the setup process:\n\n\n./setup.sh\n\n\n\nThis will take several minutes, going through the steps in these scripts:\n\n\n\n\nfrontend.sh\n\n\nbackend.sh\n\n\n\n\nOnce complete, you should have a fully functioning local environment,\nready for you to develop against!\n\n\nThere are some \noptional setup steps\n\nthat you may want to perform before continuing.\n\n\nWant to know more about what the setup scripts are doing?\n\nRead the detailed rundown.\n\n\nGet any errors? \nSee our troubleshooting tips.\n\n\nContinue following the \nusage instructions\n.\n\n\nDocker-compose installation\n\u00b6\n\n\nTools we use for developing with Docker\n\u00b6\n\n\n\n\nDocker\n: You may not need to interact directly with Docker, but you\n  should know that it's a client/server application for managing \ncontainers\n\n  (a way of running software in an isolated environment) and \nimages\n (a\n  snapshot of all of the files neccessary to run a container).\n\n\nDocker Compose\n: Compose allows you to configure and run a collection of\n  connected containers (like a web application and its database).\n\n\nDocker Machine\n: In environments where Docker Engine is not available,\n  Docker Machine can be used to create and manage Docker hosts on virtual\n  machines. For more information on Docker Machine, see the 'How do I use\n  Docker Machine' section in the \nusage guide\n.\n\n\n\n\n1. Setup your Docker environment\n\u00b6\n\n\nIf you have never installed Docker before, follow the instructions\n\nhere\n or from your operating\nsystem vendor. If you are on a mac and are unable to install the official\n\"Docker for Mac\" package, the quickstart instructions below might help.\n\n\nIf you are on a machine that is already set up to run Linux docker containers,\nplease install \nDocker Compose\n.\nIf \ndocker-compose ps\n runs without error, you can can go to step 2.\n\n\nCopy the \n.python_env_SAMPLE\n file over\n\u00b6\n\n\nThe Docker Compose setup (see \ndocker-compose.yml\n) provides the environment\nvariables defined in \n.python_env\n to the container running the Django app. If\nthis is your first time setting up the project, copy \n.python_env_SAMPLE\n to\n\n.python_env\n:\n\n\ncp -a .python_env_SAMPLE .python_env\n\n\n\nMac + Homebrew + Docker Machine + VirtualBox quickstart\n\u00b6\n\n\nStarting assumptions\n: You already have Homebrew and VirtualBox installed.\nYou can run \nbrew search docker\n without error.\n\n\nInstall Docker, Docker Machine, and Docker Compose:\n\nbrew install docker docker-compose docker-machine\n\n\nThen run \nsource mac-virtualbox-init.sh\n to initialize your Docker Machine\nsetup.\n\n\nAt this point, \ndocker-compose ps\n should run without error.\n\n\n2. Setup your frontend environment\n\u00b6\n\n\nRefer to the \nfront-end dependencies\n described above\nin the \nstandalone installation instructions\n.\n\n\n3. Run setup\n\u00b6\n\n\n./setup.sh docker\n\n\nThis will install and build the frontend and set up the docker environment.\n\n\n4. Run Docker Compose for the first time\n\u00b6\n\n\ndocker-compose up\n\n\nThis will download and/or build images, and then start the containers, as\ndescribed in the docker-compose.yml file. This will take a few minutes, or\nlonger if you are on a slow internet connection.\n\n\nWhen it's all done, you should be able to load \nhttp://localhost:8000\n in your\nbrowser, and see a database error.\n\n\n3. Setup the database\n\u00b6\n\n\nRun \n./shell.sh\n. This opens a bash shell inside your Python container.\n\n\nYou can either \nload initial data\n per the\ninstructions below, or load a database dump.\n\n\nYou could save some time and effort later (if you have access to the CFPB\nnetwork), by configuring a URL for database dumps in the \n.python_env\n file.\n\n\nCFGOV_PROD_DB_LOCATION=http://(rest of the URL)\n\n\n\nYou can get that URL at\n[GHE]/CFGOV/platform/wiki/Database-downloads#resources-available-via-s3\n\n\nWith \nCFGOV_PROD_DB_LOCATION\n in \n.python_env\n you should be able to run:\n\n\n./refresh-data.sh\n\n\nOtherwise, \nthe instructions to load a database dump\n\nbelow should be enough to get you started.\n\n\nOnce you have a database loaded, you should have a functioning copy of site\nworking at \nhttp://localhost:8000\n\n\n4. Next Steps\n\u00b6\n\n\nSee the Docker section of the \nusage\n page to continue after that.\n\n\nOptional steps\n\u00b6\n\n\nLoad initial data into database\n\u00b6\n\n\nThe \ninitial-data.sh\n script can be used to initialize a new database to make\nit easy to get started working on Wagtail. This script first ensures that all\nmigrations are applied to the database, and then does the following:\n\n\n\n\nCreates an \nadmin\n superuser with password \nadmin\n.\n\n\nIf it doesn't already exist, creates a new Wagtail home page named \nCFGOV\n,\nwith a slug of \ncfgov\n.\n\n\nUpdates the default Wagtail site to use the port defined by the\n\nDJANGO_HTTP_PORT\n environment variable, if defined; otherwise this port is\nset to 80.\n\n\nIf it doesn't already exist, creates a new\n\nwagtail-sharing\n \nSharingSite\n with\na hostname and port defined by the \nDJANGO_STAGING_HOSTNAME\n and\n\nDJANGO_HTTP_PORT\n environment variables.\n\n\n\n\nLoad a database dump\n\u00b6\n\n\nIf you're installing this fresh, the initial data you receive will not be\nas extensive as you'd probably like it to be.\n\n\nYou can get a database dump by:\n\n\n\n\nGoing to [GHE]/CFGOV/platform/wiki/Database-downloads\n\n\nSelecting one of the extractions and downloading the\n   \nproduction_django.sql.gz\n file\n\n\nRun:\n\n\n\n\n./refresh-data.sh /path/to/dump.sql.gz\n\n\n\nThe \nrefresh-data.sh\n script will apply the same changes as the\n\ninitial-data.sh\n script described above (including setting up the \nadmin\n\nsuperuser), but will not apply migrations.\n\n\nTo apply any unapplied migrations to a database created from a dump, run:\n\n\npython cfgov/manage.py migrate\n\n\n\nSet variables for working with the GovDelivery API\n\u00b6\n\n\nUncomment and set the GovDelivery environment variables in your \n.env\n file.\n\n\n\n\nNote\n\n\nGovDelivery is a third-party web service that powers our emails.\nThe API is used by subscribe forms on our website.\nUsers may decide to swap this tool out for another third-party service.\n\n\n\n\nCurious about what the setup scripts are doing?\n\u00b6\n\n\nHere's a rundown of each of the scripts called by \nsetup.sh\n and what they do.\n\n\n1. \nfrontend.sh\n\u00b6\n\n\n\n\nInitialize project dependency directories\n (\ninit\n)\n\n\n\n\nThis script first checks for an argument passed from the command line\n   that can trigger different options for different environments.\n   Since you ran it with no arguments, it will set up the dev environment.\n\n\nIt then creates a checksum for \npackage-lock.json\n (if it exists) and\n   \npackage.json\n.\n   This will be used later to determine if dependencies need to be installed.\n\n\nIt will then set some env vars for the Node dependency directories.\n1. \nClean and install project dependencies\n (\nclean_and_install\n)\n\n\nThe script will now compare the checksums to see if it needs to install\n   dependencies, or if they are already up-to-date.\n\n\nIf the checksums do not match, the script will empty out all installed\n   dependencies (\nclean\n) so the new installation can start fresh,\n   then install the latest requested dependencies (\ninstall\n).\n\n\nThe \ndevDependencies\n from \npackage.json\n are not installed\n   if the environment is production, and if it's the dev or test environment,\n   it checks to see if Protractor is globally installed.\n\n\nFinally, it creates a new checksum for future comparisons.\n1. \nRun tasks to build the project for distribution\n (\nbuild\n)\n\n\nFinally, the script runs \ngulp build\n to rebuild the front-end assets.\n   It no longer cleans first, because the gulp-changed plugin prevents\n   rebuilding assets that haven't changed since the last build.\n\n\nIf this is the production environment, it also triggers style and script\n   builds for \nondemand\n and \nnemo\n, which aren't part of a standard\n   \ngulp build\n.\n\n\n2. \nbackend.sh\n\u00b6\n\n\n\n\nNote\n\n\nbackend.sh\n is not used for our Docker setup.\n\n\n\n\n\n\nConfirm environment\n (\ninit\n)\n\n\n\n\nThis script first checks for an argument passed from the command line\n   that can trigger different options for different environments.\n   Since you ran it with no arguments, it will set up the dev environment.\n\n\nIt will then run a script to ensure that you're in a virtualenv.\n   If not, the script will end, to prevent you from accidentally installing\n   your Python dependencies globally.\n\n\n\n\nInstall project dependencies\n (\ninstall\n)\n\n\n\n\nPython dependencies are installed into the virtualenv via pip.\n   Dependencies vary slightly depending on whether we're in dev, test, or prod.\n\n\nTroubleshooting\n\u00b6\n\n\nHere are some common issues and how you can fix them:\n\n\nErrors referencing South, or other Python errors:\n\u00b6\n\n\nSince moving to Django 1.8, we use Django's built-in migration engine,\nand we no longer use South.\nIf you're getting South errors, you probably have it installed globally.\nTo solve this, from outside the virtual environment, run \npip uninstall south\n.\n\n\nIf you're getting other kinds of Python errors (for example, when running tox),\nyou may even want to go as far as uninstalling all globally-installed\nPython packages: \npip freeze | grep -v \"^-e\" | xargs pip uninstall -y\n.\nAfter doing that, you'll need to reinstall virtualenv:\n\npip install virtualenv virtualenvwrapper\n.", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#installation-and-configuration-for-cfgov-refresh", 
            "text": "", 
            "title": "Installation and configuration for cfgov-refresh"
        }, 
        {
            "location": "/installation/#clone-the-repository", 
            "text": "Using the console, navigate to the root directory in which your projects\nlive and clone this project's repository:  git clone git@github.com:cfpb/cfgov-refresh.git\ncd cfgov-refresh  You may also wish to fork the repository on GitHub and clone the resultant\npersonal fork. This is advised if you are going to be doing development on cfgov-refresh  and contributing to the project.  There are two ways to install cfgov-refresh:   Stand-alone installation  Docker-compose installation", 
            "title": "Clone the repository"
        }, 
        {
            "location": "/installation/#stand-alone-installation", 
            "text": "These instructions are somewhat specific to developing on macOS,\nbut if you're familiar with other Unix-based systems,\nit should be fairly easy to adapt them to your needs.", 
            "title": "Stand-alone installation"
        }, 
        {
            "location": "/installation/#install-system-level-requirements", 
            "text": "", 
            "title": "Install system-level requirements"
        }, 
        {
            "location": "/installation/#virtualenv-virtualenvwrapper-python-modules", 
            "text": "Install  virtualenv \nand  virtualenvwrapper \nto be able to create a local environment for your server:  pip install virtualenv virtualenvwrapper", 
            "title": "virtualenv &amp; virtualenvwrapper Python modules"
        }, 
        {
            "location": "/installation/#autoenv-module", 
            "text": "This project uses a large number of environment variables.  To automatically define environment variables and launch the virtualenv\nupon  cd ing to the project folder, install Autoenv .\nWe recommend using  Homebrew :  brew install autoenv  After installation, Homebrew will output instructions similar to:  To finish the installation, source activate.sh in your shell:\n  source /Users/[YOUR USERNAME]/homebrew/opt/autoenv/activate.sh  Run that now for your initial setup.\nAny time you run the project you\u2019ll need to run that last line, so\nif you\u2019ll be working with the project consistently,\nwe suggest adding it to your Bash profile by running:  echo 'source /Users/[YOUR USERNAME]/homebrew/opt/autoenv/activate.sh'   ~/.bash_profile  If you need to find this info again later, you can run:  brew info autoenv   Note  If you use Zsh you\u2019ll need to use zsh-autoenv ,\nbut we can\u2019t provide support for issues that may arise.", 
            "title": "Autoenv module"
        }, 
        {
            "location": "/installation/#front-end-dependencies", 
            "text": "The cfgov-refresh front end currently uses the following frameworks / tools:   Gulp : task management for pulling in assets,\n  linting and concatenating code, etc.  Less : CSS pre-processor.  Capital Framework :\n  User interface pattern-library produced by the CFPB.    Note  If you\u2019re new to Capital Framework, we encourage you to start here .     Install  Node.js  however you\u2019d like.\n   We recommend using  nvm , though.    Install  Gulp :    npm install -g gulp   Note  This project requires Node.js v8 or higher, and npm v5 or higher.", 
            "title": "Front-end dependencies"
        }, 
        {
            "location": "/installation/#webfonts", 
            "text": "The site uses a proprietary licensed font, Avenir.\nIf you want to pull this from a content delivery network (CDN),\nyou can set the @use-font-cdn \nto  true  and rebuild the assets with  gulp build .\nIf you want to install self-hosted fonts locally, you can place the font files\nin  static.in/cfgov-fonts/fonts/  and restart the local web server.\nIf you are a CFPB employee, you can perform this step with:  cd static.in/   git clone https://[GHE]/CFGOV/cfgov-fonts/ \nWhere  [GHE]  is our GitHub Enterprise URL.", 
            "title": "Webfonts"
        }, 
        {
            "location": "/installation/#set-up-your-environment", 
            "text": "The Django app relies on environment variables defined in a  .env  file. If this\nis your first time setting up the project, copy  .env_SAMPLE  to  .env  and then source  that file:  cp -a .env_SAMPLE .env\nsource .env  Each time you start a new session for working on this project, you'll need to\nget those environment variables and get your virtualenv running again.  If you setup Autoenv earlier, this will happen for you automatically when you cd  into the project directory.  If you prefer not to use Autoenv, just be sure to  source .env  every time\nyou start a new session of work on the project.", 
            "title": "Set up your environment"
        }, 
        {
            "location": "/installation/#optional-but-recommended-use-postgres-instead-of-sqlite", 
            "text": "We default to SQLite for the Django backend to make it easy to get started, but\nPostgres is our preferred database, and we recommend you consider installing it\nif you are comfortable doing this.  If you're on a Mac and use Homebrew, you can easily install Postgres:  brew install postgresql  Once it's installed, you can configure it to run as a service:  brew services start postgresql  Then create the database and associated user:  dropdb --if-exists cfgov   dropuser --if-exists cfpb\ncreateuser cfpb   createdb -O cfpb cfgov  You'll also need to update your  .env  file to comment out the line that\nspecifies SQLite as the db:  # export DATABASE_URL=sqlite:///db.sqlite3  And then uncomment the line that tells Django to use Postgres:  export DATABASE_URL=postgres://cfpb@localhost/cfgov", 
            "title": "Optional (but recommended): use Postgres instead of SQLite"
        }, 
        {
            "location": "/installation/#run-the-setup-script", 
            "text": "At this point, your machine should have everything it needs to automate the\nrest of the setup process.  If you haven't cloned this repo yet, clone it to a local folder.\nBecause related projects will need to be installed as siblings to this project,\nwe recommend putting them all in their own folder, e.g.,  ~/Projects/cf.gov .  Once cloned, from the project root ( ~/Projects/cf.gov/cfgov-refresh/ ),\nrun this command to complete the setup process:  ./setup.sh  This will take several minutes, going through the steps in these scripts:   frontend.sh  backend.sh   Once complete, you should have a fully functioning local environment,\nready for you to develop against!  There are some  optional setup steps \nthat you may want to perform before continuing.  Want to know more about what the setup scripts are doing? Read the detailed rundown.  Get any errors?  See our troubleshooting tips.  Continue following the  usage instructions .", 
            "title": "Run the setup script"
        }, 
        {
            "location": "/installation/#docker-compose-installation", 
            "text": "", 
            "title": "Docker-compose installation"
        }, 
        {
            "location": "/installation/#tools-we-use-for-developing-with-docker", 
            "text": "Docker : You may not need to interact directly with Docker, but you\n  should know that it's a client/server application for managing  containers \n  (a way of running software in an isolated environment) and  images  (a\n  snapshot of all of the files neccessary to run a container).  Docker Compose : Compose allows you to configure and run a collection of\n  connected containers (like a web application and its database).  Docker Machine : In environments where Docker Engine is not available,\n  Docker Machine can be used to create and manage Docker hosts on virtual\n  machines. For more information on Docker Machine, see the 'How do I use\n  Docker Machine' section in the  usage guide .", 
            "title": "Tools we use for developing with Docker"
        }, 
        {
            "location": "/installation/#1-setup-your-docker-environment", 
            "text": "If you have never installed Docker before, follow the instructions here  or from your operating\nsystem vendor. If you are on a mac and are unable to install the official\n\"Docker for Mac\" package, the quickstart instructions below might help.  If you are on a machine that is already set up to run Linux docker containers,\nplease install  Docker Compose .\nIf  docker-compose ps  runs without error, you can can go to step 2.", 
            "title": "1. Setup your Docker environment"
        }, 
        {
            "location": "/installation/#copy-the-python_env_sample-file-over", 
            "text": "The Docker Compose setup (see  docker-compose.yml ) provides the environment\nvariables defined in  .python_env  to the container running the Django app. If\nthis is your first time setting up the project, copy  .python_env_SAMPLE  to .python_env :  cp -a .python_env_SAMPLE .python_env", 
            "title": "Copy the .python_env_SAMPLE file over"
        }, 
        {
            "location": "/installation/#mac-homebrew-docker-machine-virtualbox-quickstart", 
            "text": "Starting assumptions : You already have Homebrew and VirtualBox installed.\nYou can run  brew search docker  without error.  Install Docker, Docker Machine, and Docker Compose: brew install docker docker-compose docker-machine  Then run  source mac-virtualbox-init.sh  to initialize your Docker Machine\nsetup.  At this point,  docker-compose ps  should run without error.", 
            "title": "Mac + Homebrew + Docker Machine + VirtualBox quickstart"
        }, 
        {
            "location": "/installation/#2-setup-your-frontend-environment", 
            "text": "Refer to the  front-end dependencies  described above\nin the  standalone installation instructions .", 
            "title": "2. Setup your frontend environment"
        }, 
        {
            "location": "/installation/#3-run-setup", 
            "text": "./setup.sh docker  This will install and build the frontend and set up the docker environment.", 
            "title": "3. Run setup"
        }, 
        {
            "location": "/installation/#4-run-docker-compose-for-the-first-time", 
            "text": "docker-compose up  This will download and/or build images, and then start the containers, as\ndescribed in the docker-compose.yml file. This will take a few minutes, or\nlonger if you are on a slow internet connection.  When it's all done, you should be able to load  http://localhost:8000  in your\nbrowser, and see a database error.", 
            "title": "4. Run Docker Compose for the first time"
        }, 
        {
            "location": "/installation/#3-setup-the-database", 
            "text": "Run  ./shell.sh . This opens a bash shell inside your Python container.  You can either  load initial data  per the\ninstructions below, or load a database dump.  You could save some time and effort later (if you have access to the CFPB\nnetwork), by configuring a URL for database dumps in the  .python_env  file.  CFGOV_PROD_DB_LOCATION=http://(rest of the URL)  You can get that URL at\n[GHE]/CFGOV/platform/wiki/Database-downloads#resources-available-via-s3  With  CFGOV_PROD_DB_LOCATION  in  .python_env  you should be able to run:  ./refresh-data.sh  Otherwise,  the instructions to load a database dump \nbelow should be enough to get you started.  Once you have a database loaded, you should have a functioning copy of site\nworking at  http://localhost:8000", 
            "title": "3. Setup the database"
        }, 
        {
            "location": "/installation/#4-next-steps", 
            "text": "See the Docker section of the  usage  page to continue after that.", 
            "title": "4. Next Steps"
        }, 
        {
            "location": "/installation/#optional-steps", 
            "text": "", 
            "title": "Optional steps"
        }, 
        {
            "location": "/installation/#load-initial-data-into-database", 
            "text": "The  initial-data.sh  script can be used to initialize a new database to make\nit easy to get started working on Wagtail. This script first ensures that all\nmigrations are applied to the database, and then does the following:   Creates an  admin  superuser with password  admin .  If it doesn't already exist, creates a new Wagtail home page named  CFGOV ,\nwith a slug of  cfgov .  Updates the default Wagtail site to use the port defined by the DJANGO_HTTP_PORT  environment variable, if defined; otherwise this port is\nset to 80.  If it doesn't already exist, creates a new wagtail-sharing   SharingSite  with\na hostname and port defined by the  DJANGO_STAGING_HOSTNAME  and DJANGO_HTTP_PORT  environment variables.", 
            "title": "Load initial data into database"
        }, 
        {
            "location": "/installation/#load-a-database-dump", 
            "text": "If you're installing this fresh, the initial data you receive will not be\nas extensive as you'd probably like it to be.  You can get a database dump by:   Going to [GHE]/CFGOV/platform/wiki/Database-downloads  Selecting one of the extractions and downloading the\n    production_django.sql.gz  file  Run:   ./refresh-data.sh /path/to/dump.sql.gz  The  refresh-data.sh  script will apply the same changes as the initial-data.sh  script described above (including setting up the  admin \nsuperuser), but will not apply migrations.  To apply any unapplied migrations to a database created from a dump, run:  python cfgov/manage.py migrate", 
            "title": "Load a database dump"
        }, 
        {
            "location": "/installation/#set-variables-for-working-with-the-govdelivery-api", 
            "text": "Uncomment and set the GovDelivery environment variables in your  .env  file.   Note  GovDelivery is a third-party web service that powers our emails.\nThe API is used by subscribe forms on our website.\nUsers may decide to swap this tool out for another third-party service.", 
            "title": "Set variables for working with the GovDelivery API"
        }, 
        {
            "location": "/installation/#curious-about-what-the-setup-scripts-are-doing", 
            "text": "Here's a rundown of each of the scripts called by  setup.sh  and what they do.", 
            "title": "Curious about what the setup scripts are doing?"
        }, 
        {
            "location": "/installation/#1-frontendsh", 
            "text": "Initialize project dependency directories  ( init )   This script first checks for an argument passed from the command line\n   that can trigger different options for different environments.\n   Since you ran it with no arguments, it will set up the dev environment.  It then creates a checksum for  package-lock.json  (if it exists) and\n    package.json .\n   This will be used later to determine if dependencies need to be installed.  It will then set some env vars for the Node dependency directories.\n1.  Clean and install project dependencies  ( clean_and_install )  The script will now compare the checksums to see if it needs to install\n   dependencies, or if they are already up-to-date.  If the checksums do not match, the script will empty out all installed\n   dependencies ( clean ) so the new installation can start fresh,\n   then install the latest requested dependencies ( install ).  The  devDependencies  from  package.json  are not installed\n   if the environment is production, and if it's the dev or test environment,\n   it checks to see if Protractor is globally installed.  Finally, it creates a new checksum for future comparisons.\n1.  Run tasks to build the project for distribution  ( build )  Finally, the script runs  gulp build  to rebuild the front-end assets.\n   It no longer cleans first, because the gulp-changed plugin prevents\n   rebuilding assets that haven't changed since the last build.  If this is the production environment, it also triggers style and script\n   builds for  ondemand  and  nemo , which aren't part of a standard\n    gulp build .", 
            "title": "1. frontend.sh"
        }, 
        {
            "location": "/installation/#2-backendsh", 
            "text": "Note  backend.sh  is not used for our Docker setup.    Confirm environment  ( init )   This script first checks for an argument passed from the command line\n   that can trigger different options for different environments.\n   Since you ran it with no arguments, it will set up the dev environment.  It will then run a script to ensure that you're in a virtualenv.\n   If not, the script will end, to prevent you from accidentally installing\n   your Python dependencies globally.   Install project dependencies  ( install )   Python dependencies are installed into the virtualenv via pip.\n   Dependencies vary slightly depending on whether we're in dev, test, or prod.", 
            "title": "2. backend.sh"
        }, 
        {
            "location": "/installation/#troubleshooting", 
            "text": "Here are some common issues and how you can fix them:", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/installation/#errors-referencing-south-or-other-python-errors", 
            "text": "Since moving to Django 1.8, we use Django's built-in migration engine,\nand we no longer use South.\nIf you're getting South errors, you probably have it installed globally.\nTo solve this, from outside the virtual environment, run  pip uninstall south .  If you're getting other kinds of Python errors (for example, when running tox),\nyou may even want to go as far as uninstalling all globally-installed\nPython packages:  pip freeze | grep -v \"^-e\" | xargs pip uninstall -y .\nAfter doing that, you'll need to reinstall virtualenv: pip install virtualenv virtualenvwrapper .", 
            "title": "Errors referencing South, or other Python errors:"
        }, 
        {
            "location": "/usage/", 
            "text": "Usage: Stand Alone\n\u00b6\n\n\nYou will generally have three tabs (or windows) open in your terminal,\nwhich will be used for:\n\n\n\n\nGit operations\n.\n    Perform Git operations and general development in the repository,\n    such as \ngit checkout master\n.\n\n\nElasticsearch\n.\n    Run an Elasticsearch (ES) instance.\n    See instructions \nbelow\n.\n\n\nDjango server\n. Start and stop the web server.\n    Server is started with \n./runserver.sh\n,\n    but see more details \nbelow\n.\n\n\n\n\nWhat follows are the specific steps for each of these tabs.\n\n\n1. Git operations\n\u00b6\n\n\nFrom this tab you can do Git operations,\nsuch as checking out our master branch:\n\n\ngit checkout master\n\n\n\nUpdating all dependencies\n\u00b6\n\n\nEach time you fetch from the upstream repository (this repo), run \n./setup.sh\n.\nThis setup script will remove and reinstall the project dependencies\nand rebuild the site's JavaScript and CSS assets.\n\n\n\n\nNote\n\n\nYou may also run \n./backend.sh\n or \n./frontend.sh\n\nif you only want to re-build the backend or front-end, respectively.\n\n\n\n\nSetting environments\n\u00b6\n\n\nThe \nNODE_ENV\n environment variable can be set in your \n.env\n file to either\n\ndevelopment\n or \nproduction\n, which will affect how the build is made and what\ngulp tasks are available. To install dependencies of one environment\nor the other run \n./frontend.sh\n (dependencies and devDependencies)\nor \n./frontend.sh production\n (dependencies but not devDependencies).\n\n\n2. Run Elasticsearch (optional)\n\u00b6\n\n\nElasticsearch is needed for certain pieces of this project but is not a\nrequirement for basic functionality.\n\n\nIf Elasticsearch is installed via \nHomebrew\n, you can see\ninstructions for running manually or as a background service using:\n\n\nbrew info elasticsearch\n\n\n\nTypically to run Elasticsearch as a background service you can run:\n\n\nbrew services start elasticsearch\n\n\n\n3. Launch Site\n\u00b6\n\n\nFirst, move into the \ncfgov-refresh\n project directory\nand ready your environment:\n\n\n# Use the cfgov-refresh virtualenv.\nworkon cfgov-refresh\n\n# cd into this directory (if you aren't already there)\ncd cfgov-refresh\n\n\n\nFrom the project root, start the Django server:\n\n\n./runserver.sh\n\n\n\n\n\nNote\n\n\nIf prompted to migrate database changes,\nstop the server with \nctrl\n + \nc\n and run these commands:\n\n\n\n\npython cfgov/manage.py migrate\n./initial-data.sh\n./runserver.sh\n\n\n\nTo view the site browse to: \nhttp://localhost:8000\n\n\n\n\nUsing a different port\n\n\nIf you want to run the server at a port other than 8000 use\n\n\npython cfgov/manage.py runserver \nport number\n\n\nSpecify an alternate port number, e.g. \n8001\n.\n\n\n\n\nTo view the Wagtail admin login,\nbrowse to \nhttp://localhost:8000/admin\n and login with username \nadmin\n\nand password \nadmin\n (created in \ninitial-data.sh\n above; note that this\npassword will expire after 60 days).\n\n\n\n\nUsing HTTPS locally\n\n\nTo access a local server using HTTPS use\n\n\n./runserver.sh ssl\n\n\nYou'll need to ignore any browser certificate errors.\n\n\n\n\nAvailable Gulp Tasks\n\u00b6\n\n\nThere are a number of important gulp tasks,\nparticularly \ngulp build\n and \ngulp test\n,\nwhich will build the project and test it, respectively.\nUsing the \ngulp --tasks\n command you can view all available tasks.\nThe important ones are listed below:\n\n\ngulp build           # Concatenate, optimize, and copy source files to the production /dist/ directory.\ngulp clean           # Remove the contents of the production /dist/ directory.\ngulp lint            # Lint the scripts and build files.\ngulp docs            # Generate JSDocs from the scripts.\ngulp test            # Run linting, unit and acceptance tests (see below).\ngulp test:unit       # Run only unit tests on source code.\ngulp test:acceptance # Run only acceptance (in-browser) tests on production code.\ngulp audit           # Run code quality audits.\n\n\n\nUsage: Docker\n\u00b6\n\n\nMuch of the guidance above for the \"stand-alone\" set-up still stands, and it\nis worth reviewing in full. Here are some things that might be different:\n\n\n\n\ndocker-compose\n takes care of running Elasticsearch for you, and all\nElasticsearch, Postgres, and Python output will be shown in a single Terminal\nwindow or tab. (wherever you run \ndocker-compose up\n)\n\n\nmanage.py\n commands can only be run after you've opened up a terminal in the\nPython container, which you can do with \n./shell.sh\n\n\nThere is not \nyet\n a good way to use SSL/HTTPS, but that is in the works\n\n\nYou won't ever need to use \nbackend.sh\n or \nrunserver.sh\n\n\n\n\nHow do I...\n\u00b6\n\n\nUse Docker Machine\n\u00b6\n\n\nIf you used \nmac-virtualbox-init.sh\n, then we used Docker Machine to create a\nVirtualBox VM, running the Docker server. Here are some useful \ndocker-machine\n\ncommands:\n\n\n\n\nStart and stop the VM with  \ndocker-machine start\n and \ndocker-machine stop\n\n\nget the current machine IP with \ndocker-machine ip\n\n\nif for some reason you want to start over, \ndocker-machine rm default\n, and\n  \nsource mac-virtualbox-init.sh\n\n\n\n\nTo enable Docker and Docker Compose commands, you'll always first need to run\nthis command in any new shell:\n\n\neval $(docker-machine env)\n\n\nIt may be helpful to run \ndocker-machine env\n by itself, so you understand\nwhat's happening. Those variables are what allows \ndocker-compose\n and the\n\ndocker\n command line tool, running natively on your Mac, to connect to the\nDocker server running inside VirtualBox.\n\n\nIf you use autoenv (described in the stand-alone intructions) or something\nsimilar, you might consider adding \neval $(docker-machine env)\n to your .env\nfile. You could also achieve the same results (and start the VM if it's not\nrunning yet) with \nsource mac-virtualbox-init.sh\n\n\nAny further Docker documentation will assume you are either in a shell where\nyou have already run \neval $(docker-machine env)\n, or you are in an environment\nwhere that's not neccessary.\n\n\nRun manage.py commands like migrate, shell, and dbshell, and shell scripts like refresh-data.sh\n\u00b6\n\n\nrun \n./shell.sh\n to open up a shell \ninside\n the Python container. From there,\ncommands like \ncfgov/manage.py migrate\n should run as expected.\n\n\nThe same goes for scripts like \n./refresh-data.sh\n and \n./initial-data.sh\n \u2013\nthey will work as expected once you're inside the container.\n\n\nIn addition you can run single commands by passing them as arguments to\n\nshell.sh\n, for example:\n\n\n./shell.sh cfgov/manage.py migrate\n\n\nUse PDB\n\u00b6\n\n\nRun \n./attach.sh\n to connect to the TTY session where \nmanage.py runserver\n is\nrunning. If the app is paused at a PDB prompt, this is where you can access it.\n\n\nHandle updates to Python requirements\n\u00b6\n\n\nIf Compose is running, stop it with CTRL-C. Run:\n\n\ndocker-compose build python\n\n\nThis will update your Python image. The next time you run \ndocker-compose up\n,\nthe new requirements will be in place.\n\n\nSet environment variables\n\u00b6\n\n\nYour shell environment variables (and the variables in your .env file, if you\nare using one) are not visible to applications running in Docker. If you need\nto set variables that will be visible to Django, and in \n./shell.sh\n, you'll\nneed to set them in the .python_env file, and restart the python container (it\nmight be simpler to simple stop compose with ctrl-c, and start it again with\n\ndocker-compose up\n)\n\n\n.python_env is \nnot\n a shell script, like your .env file, ~/.bash_profile, etc.\nSee the \nDocker Compose docs\n\n\nGet familiar with Docker Compose, and our configuration\n\u00b6\n\n\ndocker-compose.yml contains a sort of \"recipe\" for running the site. Each entry\nin the Compose file describes a component of our application stack (Postgres,\nElasticsearch, and Python), and either points to a public image on Dockerhub,\nor to a Dockerfile in cfgov-refresh. You can learn a lot more about Compose\nfiles in \nthe docs\n\n\nSimilarly, a Dockerfile contains instructions for transforming some base image,\nto one that suits our needs. The Dockerfile sitting in the top level of\ncfgov-refresh is probably the most interesting. It starts with\n\nthe public CentOS:7 image\n, and installs\neverything else neccessary to run our Python dependencies and the Django app\nitself.  This file will only be executed:\n\n\n\n\nthe first time you run \ndocker-compose up\n (or the first time after you\nre-create the Docker Machine VM)\n\n\nany time you run \ndocker-compose build\n\n\n\n\nThat's why you need to run \ndocker-compose build\n after any changes to\n/requirements/\n\n\nThere are other compose subcommands you might be interested in. Consider\n\nlearning about\n\n\nbuild\n, \nrestarts\n, \nlogs\n, \nps\n, \ntop\n, and the \n-d\n option for \nup\n.\n\n\nDevelop satellite apps\n\u00b6\n\n\nCheck out any apps you are developing into the develop-apps directory. These\nwill automatically be added to the\n\nPYTHONPATH\n,\nand apps contained within will be importable from Python running in the\ncontainer.\n\n\nFor example, if your app is called 'foobar', in a repo called foobar-project,\nyou could clone foobar-project in to develop apps:\n\n\ngit clone https://github.com/myorg/foobar-project\n\n\n... which will create a directory at develop-apps/foobar-project. Assuming\n'foobar' is at the top-level of 'foobar-project', you should be able to\nimport it from your python code:\n\n\nimport foobar\n\n\n\nrunserver has crashed! How do I start it again\n\u00b6\n\n\nIn a separate terminal window or tab, running \ndocker-compose up python\n should\nrestart the server.", 
            "title": "Usage"
        }, 
        {
            "location": "/usage/#usage-stand-alone", 
            "text": "You will generally have three tabs (or windows) open in your terminal,\nwhich will be used for:   Git operations .\n    Perform Git operations and general development in the repository,\n    such as  git checkout master .  Elasticsearch .\n    Run an Elasticsearch (ES) instance.\n    See instructions  below .  Django server . Start and stop the web server.\n    Server is started with  ./runserver.sh ,\n    but see more details  below .   What follows are the specific steps for each of these tabs.", 
            "title": "Usage: Stand Alone"
        }, 
        {
            "location": "/usage/#1-git-operations", 
            "text": "From this tab you can do Git operations,\nsuch as checking out our master branch:  git checkout master", 
            "title": "1. Git operations"
        }, 
        {
            "location": "/usage/#updating-all-dependencies", 
            "text": "Each time you fetch from the upstream repository (this repo), run  ./setup.sh .\nThis setup script will remove and reinstall the project dependencies\nand rebuild the site's JavaScript and CSS assets.   Note  You may also run  ./backend.sh  or  ./frontend.sh \nif you only want to re-build the backend or front-end, respectively.", 
            "title": "Updating all dependencies"
        }, 
        {
            "location": "/usage/#setting-environments", 
            "text": "The  NODE_ENV  environment variable can be set in your  .env  file to either development  or  production , which will affect how the build is made and what\ngulp tasks are available. To install dependencies of one environment\nor the other run  ./frontend.sh  (dependencies and devDependencies)\nor  ./frontend.sh production  (dependencies but not devDependencies).", 
            "title": "Setting environments"
        }, 
        {
            "location": "/usage/#2-run-elasticsearch-optional", 
            "text": "Elasticsearch is needed for certain pieces of this project but is not a\nrequirement for basic functionality.  If Elasticsearch is installed via  Homebrew , you can see\ninstructions for running manually or as a background service using:  brew info elasticsearch  Typically to run Elasticsearch as a background service you can run:  brew services start elasticsearch", 
            "title": "2. Run Elasticsearch (optional)"
        }, 
        {
            "location": "/usage/#3-launch-site", 
            "text": "First, move into the  cfgov-refresh  project directory\nand ready your environment:  # Use the cfgov-refresh virtualenv.\nworkon cfgov-refresh\n\n# cd into this directory (if you aren't already there)\ncd cfgov-refresh  From the project root, start the Django server:  ./runserver.sh   Note  If prompted to migrate database changes,\nstop the server with  ctrl  +  c  and run these commands:   python cfgov/manage.py migrate\n./initial-data.sh\n./runserver.sh  To view the site browse to:  http://localhost:8000   Using a different port  If you want to run the server at a port other than 8000 use  python cfgov/manage.py runserver  port number  Specify an alternate port number, e.g.  8001 .   To view the Wagtail admin login,\nbrowse to  http://localhost:8000/admin  and login with username  admin \nand password  admin  (created in  initial-data.sh  above; note that this\npassword will expire after 60 days).   Using HTTPS locally  To access a local server using HTTPS use  ./runserver.sh ssl  You'll need to ignore any browser certificate errors.", 
            "title": "3. Launch Site"
        }, 
        {
            "location": "/usage/#available-gulp-tasks", 
            "text": "There are a number of important gulp tasks,\nparticularly  gulp build  and  gulp test ,\nwhich will build the project and test it, respectively.\nUsing the  gulp --tasks  command you can view all available tasks.\nThe important ones are listed below:  gulp build           # Concatenate, optimize, and copy source files to the production /dist/ directory.\ngulp clean           # Remove the contents of the production /dist/ directory.\ngulp lint            # Lint the scripts and build files.\ngulp docs            # Generate JSDocs from the scripts.\ngulp test            # Run linting, unit and acceptance tests (see below).\ngulp test:unit       # Run only unit tests on source code.\ngulp test:acceptance # Run only acceptance (in-browser) tests on production code.\ngulp audit           # Run code quality audits.", 
            "title": "Available Gulp Tasks"
        }, 
        {
            "location": "/usage/#usage-docker", 
            "text": "Much of the guidance above for the \"stand-alone\" set-up still stands, and it\nis worth reviewing in full. Here are some things that might be different:   docker-compose  takes care of running Elasticsearch for you, and all\nElasticsearch, Postgres, and Python output will be shown in a single Terminal\nwindow or tab. (wherever you run  docker-compose up )  manage.py  commands can only be run after you've opened up a terminal in the\nPython container, which you can do with  ./shell.sh  There is not  yet  a good way to use SSL/HTTPS, but that is in the works  You won't ever need to use  backend.sh  or  runserver.sh", 
            "title": "Usage: Docker"
        }, 
        {
            "location": "/usage/#how-do-i", 
            "text": "", 
            "title": "How do I..."
        }, 
        {
            "location": "/usage/#use-docker-machine", 
            "text": "If you used  mac-virtualbox-init.sh , then we used Docker Machine to create a\nVirtualBox VM, running the Docker server. Here are some useful  docker-machine \ncommands:   Start and stop the VM with   docker-machine start  and  docker-machine stop  get the current machine IP with  docker-machine ip  if for some reason you want to start over,  docker-machine rm default , and\n   source mac-virtualbox-init.sh   To enable Docker and Docker Compose commands, you'll always first need to run\nthis command in any new shell:  eval $(docker-machine env)  It may be helpful to run  docker-machine env  by itself, so you understand\nwhat's happening. Those variables are what allows  docker-compose  and the docker  command line tool, running natively on your Mac, to connect to the\nDocker server running inside VirtualBox.  If you use autoenv (described in the stand-alone intructions) or something\nsimilar, you might consider adding  eval $(docker-machine env)  to your .env\nfile. You could also achieve the same results (and start the VM if it's not\nrunning yet) with  source mac-virtualbox-init.sh  Any further Docker documentation will assume you are either in a shell where\nyou have already run  eval $(docker-machine env) , or you are in an environment\nwhere that's not neccessary.", 
            "title": "Use Docker Machine"
        }, 
        {
            "location": "/usage/#run-managepy-commands-like-migrate-shell-and-dbshell-and-shell-scripts-like-refresh-datash", 
            "text": "run  ./shell.sh  to open up a shell  inside  the Python container. From there,\ncommands like  cfgov/manage.py migrate  should run as expected.  The same goes for scripts like  ./refresh-data.sh  and  ./initial-data.sh  \u2013\nthey will work as expected once you're inside the container.  In addition you can run single commands by passing them as arguments to shell.sh , for example:  ./shell.sh cfgov/manage.py migrate", 
            "title": "Run manage.py commands like migrate, shell, and dbshell, and shell scripts like refresh-data.sh"
        }, 
        {
            "location": "/usage/#use-pdb", 
            "text": "Run  ./attach.sh  to connect to the TTY session where  manage.py runserver  is\nrunning. If the app is paused at a PDB prompt, this is where you can access it.", 
            "title": "Use PDB"
        }, 
        {
            "location": "/usage/#handle-updates-to-python-requirements", 
            "text": "If Compose is running, stop it with CTRL-C. Run:  docker-compose build python  This will update your Python image. The next time you run  docker-compose up ,\nthe new requirements will be in place.", 
            "title": "Handle updates to Python requirements"
        }, 
        {
            "location": "/usage/#set-environment-variables", 
            "text": "Your shell environment variables (and the variables in your .env file, if you\nare using one) are not visible to applications running in Docker. If you need\nto set variables that will be visible to Django, and in  ./shell.sh , you'll\nneed to set them in the .python_env file, and restart the python container (it\nmight be simpler to simple stop compose with ctrl-c, and start it again with docker-compose up )  .python_env is  not  a shell script, like your .env file, ~/.bash_profile, etc.\nSee the  Docker Compose docs", 
            "title": "Set environment variables"
        }, 
        {
            "location": "/usage/#get-familiar-with-docker-compose-and-our-configuration", 
            "text": "docker-compose.yml contains a sort of \"recipe\" for running the site. Each entry\nin the Compose file describes a component of our application stack (Postgres,\nElasticsearch, and Python), and either points to a public image on Dockerhub,\nor to a Dockerfile in cfgov-refresh. You can learn a lot more about Compose\nfiles in  the docs  Similarly, a Dockerfile contains instructions for transforming some base image,\nto one that suits our needs. The Dockerfile sitting in the top level of\ncfgov-refresh is probably the most interesting. It starts with the public CentOS:7 image , and installs\neverything else neccessary to run our Python dependencies and the Django app\nitself.  This file will only be executed:   the first time you run  docker-compose up  (or the first time after you\nre-create the Docker Machine VM)  any time you run  docker-compose build   That's why you need to run  docker-compose build  after any changes to\n/requirements/  There are other compose subcommands you might be interested in. Consider learning about  build ,  restarts ,  logs ,  ps ,  top , and the  -d  option for  up .", 
            "title": "Get familiar with Docker Compose, and our configuration"
        }, 
        {
            "location": "/usage/#develop-satellite-apps", 
            "text": "Check out any apps you are developing into the develop-apps directory. These\nwill automatically be added to the PYTHONPATH ,\nand apps contained within will be importable from Python running in the\ncontainer.  For example, if your app is called 'foobar', in a repo called foobar-project,\nyou could clone foobar-project in to develop apps:  git clone https://github.com/myorg/foobar-project  ... which will create a directory at develop-apps/foobar-project. Assuming\n'foobar' is at the top-level of 'foobar-project', you should be able to\nimport it from your python code:  import foobar", 
            "title": "Develop satellite apps"
        }, 
        {
            "location": "/usage/#runserver-has-crashed-how-do-i-start-it-again", 
            "text": "In a separate terminal window or tab, running  docker-compose up python  should\nrestart the server.", 
            "title": "runserver has crashed! How do I start it again"
        }, 
        {
            "location": "/new-projects/", 
            "text": "Setting up new projects\n\u00b6\n\n\nAll new code should start in the \ncfgov-refresh repository\n unless the following is true:\n\n\n\n\nIt does not require integration with CMS\n\n\nIt is not expected to match the look and feel of the larger site (in fact \"very different\" is preferable to \"almost the same\")\n\n\nIt must be pip installable like any other dependency. \n\n\n\n\nIf a project meets this criteria, it is important to note that while the app itself is not necessarily tied to the cf.gov platform\u2019s release cadence, its dependencies are. Such projects must also maintain it's own continuous integration pipeline and build server.\n\n\nFor everything else, all code in the master branch is subject to a regular release cadence. Features that must go live on a certain date should be hidden by feature flags. Deployments should not be timed to coincide with announcements, press releases, speeches, or other events. The code should be already deployed and waiting for the feature to be turned on by a site manager. See \u201cFeature Flags\u201d.\n\n\nRather than using \u201cclassic\u201d Django views added to urls.py, when feasible an app should provide singleton Wagtail Page. See \u201cWagtail Pages\u201d.\n\n\nDecision Matrix\n\u00b6\n\n\n\n\n\n\n\n\nProduct\n\n\nContent Pages\n\n\nAPIs\n\n\nHTML5 API Clients (\"single page apps\")\n\n\nTraditional Web Apps\n\n\n\n\n\n\n\n\n\n\nWhat to build\n\n\nWagtail page types and templates\n\n\nDjango app using Django REST Framework\n\n\nThe API (if needed) and Wagtail page type and template to host the client\n\n\nA standard models / forms / views-based Django app. Often calling internal/external APIs\n\n\n\n\n\n\nWhere does the code live\n\n\ncfgov-refresh\n\n\ncfgov-refresh (see exceptions)\n\n\ncfgov-refresh\n\n\ncfgov-refresh (see exceptions)\n\n\n\n\n\n\nHow to start\n\n\nExtend our existing library of page types and molecules\n\n\ncreate a Django app in the \"api's\" namespace\n\n\nBuild the API first, then create a wagtail page to host the tool\n\n\nCreate a Django app at the top level of the repo. When feasible, consider providing Wagtail page-types instead of traditional views\n\n\n\n\n\n\nHow to ship\n\n\nWith release cycle\n\n\nWith release cycle\n\n\nConsider getting APIs deployed well in advance\n\n\nwith release cycle\n\n\n\n\n\n\nHow to change\n\n\nSee below\n\n\nWith the release cycle\n\n\nUse \nAPI versioning\n to avoid breaking existing code\n\n\nSee below\n\n\n\n\n\n\n\n\nHow to handle Wagtail changes\n\u00b6\n\n\nMinor visual updates to a page\n\u00b6\n\n\n\n\nmake the changes as part of the release cadence\n\n\n\n\nExtensive visual changes to a page\n\u00b6\n\n\n\n\ncreate a new template to reflect the new design\n\n\nedit the page type to allow for switching between old and new templates.\n\n\non build and staging servers, feel free to switch back and forth between the designs\n\n\n\n\nVisual and minor data model changes\n\u00b6\n\n\n\n\nmake the data model changes in such a way that doesn't break the current template\n\n\nfollow the \"extensive visual changes to a page\" guidance above to make the visual changes\n\n\n\n\nMajor data model changes\n\u00b6\n\n\n\n\ncreate a new page type, and the corresponding template\n\n\nEditors can then replace the old page with the new one, at will\n\n\n\n\nFront-end Resources\n\u00b6\n\n\nFront-end resources should conform to \nCFPB development standards\n and should use atomic elements, organisms, existing structure and convention. When applicable, front-end components should be added to Capital Framework using atomic design principles.\n\n\nProjects that will be part of cfgov but live in their own repositories should:\n\n\n\n\nfollow file-naming conventions for their front-end resources to avoid collisions (eg, project_name.js rather than main.js) OR follow resource folder structure conventions\n\n\nwhere possible, follow front-end guidelines/templates for new projects, including build processes and testing setup\n\n\nwhere necessary, follow a suggested approach for sharing resources (JavaScript/CSS) that are internal to cfgov-refresh", 
            "title": "New projects"
        }, 
        {
            "location": "/new-projects/#setting-up-new-projects", 
            "text": "All new code should start in the  cfgov-refresh repository  unless the following is true:   It does not require integration with CMS  It is not expected to match the look and feel of the larger site (in fact \"very different\" is preferable to \"almost the same\")  It must be pip installable like any other dependency.    If a project meets this criteria, it is important to note that while the app itself is not necessarily tied to the cf.gov platform\u2019s release cadence, its dependencies are. Such projects must also maintain it's own continuous integration pipeline and build server.  For everything else, all code in the master branch is subject to a regular release cadence. Features that must go live on a certain date should be hidden by feature flags. Deployments should not be timed to coincide with announcements, press releases, speeches, or other events. The code should be already deployed and waiting for the feature to be turned on by a site manager. See \u201cFeature Flags\u201d.  Rather than using \u201cclassic\u201d Django views added to urls.py, when feasible an app should provide singleton Wagtail Page. See \u201cWagtail Pages\u201d.", 
            "title": "Setting up new projects"
        }, 
        {
            "location": "/new-projects/#decision-matrix", 
            "text": "Product  Content Pages  APIs  HTML5 API Clients (\"single page apps\")  Traditional Web Apps      What to build  Wagtail page types and templates  Django app using Django REST Framework  The API (if needed) and Wagtail page type and template to host the client  A standard models / forms / views-based Django app. Often calling internal/external APIs    Where does the code live  cfgov-refresh  cfgov-refresh (see exceptions)  cfgov-refresh  cfgov-refresh (see exceptions)    How to start  Extend our existing library of page types and molecules  create a Django app in the \"api's\" namespace  Build the API first, then create a wagtail page to host the tool  Create a Django app at the top level of the repo. When feasible, consider providing Wagtail page-types instead of traditional views    How to ship  With release cycle  With release cycle  Consider getting APIs deployed well in advance  with release cycle    How to change  See below  With the release cycle  Use  API versioning  to avoid breaking existing code  See below", 
            "title": "Decision Matrix"
        }, 
        {
            "location": "/new-projects/#how-to-handle-wagtail-changes", 
            "text": "", 
            "title": "How to handle Wagtail changes"
        }, 
        {
            "location": "/new-projects/#minor-visual-updates-to-a-page", 
            "text": "make the changes as part of the release cadence", 
            "title": "Minor visual updates to a page"
        }, 
        {
            "location": "/new-projects/#extensive-visual-changes-to-a-page", 
            "text": "create a new template to reflect the new design  edit the page type to allow for switching between old and new templates.  on build and staging servers, feel free to switch back and forth between the designs", 
            "title": "Extensive visual changes to a page"
        }, 
        {
            "location": "/new-projects/#visual-and-minor-data-model-changes", 
            "text": "make the data model changes in such a way that doesn't break the current template  follow the \"extensive visual changes to a page\" guidance above to make the visual changes", 
            "title": "Visual and minor data model changes"
        }, 
        {
            "location": "/new-projects/#major-data-model-changes", 
            "text": "create a new page type, and the corresponding template  Editors can then replace the old page with the new one, at will", 
            "title": "Major data model changes"
        }, 
        {
            "location": "/new-projects/#front-end-resources", 
            "text": "Front-end resources should conform to  CFPB development standards  and should use atomic elements, organisms, existing structure and convention. When applicable, front-end components should be added to Capital Framework using atomic design principles.  Projects that will be part of cfgov but live in their own repositories should:   follow file-naming conventions for their front-end resources to avoid collisions (eg, project_name.js rather than main.js) OR follow resource folder structure conventions  where possible, follow front-end guidelines/templates for new projects, including build processes and testing setup  where necessary, follow a suggested approach for sharing resources (JavaScript/CSS) that are internal to cfgov-refresh", 
            "title": "Front-end Resources"
        }, 
        {
            "location": "/branching-merging/", 
            "text": "Branching and merging\n\u00b6\n\n\nBranches should be named descriptively, preferably in some way that indicates whether they are short-lived feature branches or longer-lived development branches. Short-lived feature branches should be deleted once they are merged into master. \n\n\nAll pull requests to merge into master must be reviewed by at least one member of the cf.gov platform team. The cf.gov platform team will ensure that these reviews happen in a timely manner. To ensure timely code reviews, please tag all PRs to master with @cfpb/cfgov-backends and @cfpb/cfgov-frontends as appropriate.\n\n\nWhen reviewing pull requests, it is important to distinguish between explicit blockers and things that can be addressed in the future or would be nice to have. The latter two can be indicated with 'TODO'. This is best as a simple top-level post after review to summarize the review.\n\n\nThe cfgov-refresh repository makes use of automated testing and linting to ensure the quality, consistency, and readability of the codebase. All pull requests to master must pass all automated tests and must not reduce the code coverage of the codebase. It is the responsibility of the submitter to ensure that the tests pass.\n\n\nPull requests that are \nnot\n to master must use GitHub labels in such a way that individuals who are responsible for reviewing those pull requests can easily find them. Pull requests that are works-in-progress must be clearly labeled as such.\n\n\nGenerally, teams working on cf.gov projects should create and collaborate on feature branches, with frequent merges back to master. Teams are responsible for governing their own branches and forks, these guidelines apply to master.", 
            "title": "Branching and merging"
        }, 
        {
            "location": "/branching-merging/#branching-and-merging", 
            "text": "Branches should be named descriptively, preferably in some way that indicates whether they are short-lived feature branches or longer-lived development branches. Short-lived feature branches should be deleted once they are merged into master.   All pull requests to merge into master must be reviewed by at least one member of the cf.gov platform team. The cf.gov platform team will ensure that these reviews happen in a timely manner. To ensure timely code reviews, please tag all PRs to master with @cfpb/cfgov-backends and @cfpb/cfgov-frontends as appropriate.  When reviewing pull requests, it is important to distinguish between explicit blockers and things that can be addressed in the future or would be nice to have. The latter two can be indicated with 'TODO'. This is best as a simple top-level post after review to summarize the review.  The cfgov-refresh repository makes use of automated testing and linting to ensure the quality, consistency, and readability of the codebase. All pull requests to master must pass all automated tests and must not reduce the code coverage of the codebase. It is the responsibility of the submitter to ensure that the tests pass.  Pull requests that are  not  to master must use GitHub labels in such a way that individuals who are responsible for reviewing those pull requests can easily find them. Pull requests that are works-in-progress must be clearly labeled as such.  Generally, teams working on cf.gov projects should create and collaborate on feature branches, with frequent merges back to master. Teams are responsible for governing their own branches and forks, these guidelines apply to master.", 
            "title": "Branching and merging"
        }, 
        {
            "location": "/feature-flags/", 
            "text": "Feature flags\n\u00b6\n\n\nFeature flags are implemented using our \nWagtail-Flags\n app. The \nREADME\n contains an overview and examples of how to use feature flags in Wagtail.\n\n\nThis document covers how to add and use feature flags with cfgov-refresh and the conventions we have around their use.\n\n\n\n\nAdding a flag\n\n\nChecking a flag\n\n\nIn templates\n\n\nJinja2\n\n\nDjango\n\n\n\n\n\n\nIn code\n\n\nIn URLs\n\n\n\n\n\n\nEnabling a flag\n\n\nHard-coded conditions\n\n\nDatabase conditions\n\n\n\n\n\n\nSatellite apps\n\n\nHygiene\n\n\n\n\nAdding a flag\n\u00b6\n\n\nFeature flags are defined in code in the \ncfgov/settings/base.py\n file as part of the \nFLAGS\n setting. Each flag consists of a single string and a Python dictionary (\n{}\n) of its hard-coded conditions (see \nEnabling a flag\n below).\n\n\nFLAGS = {\n    # Beta banner, seen on beta.consumerfinance.gov\n    # When enabled, a banner appears across the top of the site proclaiming\n    # \nThis beta site is a work in progress.\n\n    'BETA_NOTICE': {},\n}\n\n\n\nBy convention our flag names are all uppercase, with underscores instead of whitespace. A comment is expected above each flag with a short description fo what happens when it is enabled.\n\n\nChecking a flag\n\u00b6\n\n\nFlags can be checked either in Python code or in Django or Jinja2 template files. See the full \nWagtail Flags API is documented \n for more information.\n\n\nIn templates\n\u00b6\n\n\nJinja2\n\u00b6\n\n\nMost of cfgov-refresh's templates are Jinja2. In these templates, two template functions are provided, \nflag_enabled\n and \nflag_disabled\n. Each takes a flag name as its first argument and request` object as the second.\n\n\nflag_enabled('MY_FLAG', request)\n will return \nTrue\n if the conditions under which \nMY_FLAG\n is enabled \nare\n met.\n\n\nflag_disabled('MY_FLAG', request)\n will return \nTrue\n if the conditions under which \nMY_FLAG\n is enabled \nare not\n met.\n\n\nSee \nEnabling a flag\n below for more on flag conditions.\n\n\nAn example is \nthe \nBETA_NOTICE flag\n as implemented in \nheader.html\n:\n\n\n{% if flag_enabled('BETA_NOTICE', request) and show_banner %}\n\ndiv class=\nm-global-banner\n\n    \ndiv class=\nwrapper\n                wrapper__match-content\n                o-expandable\n                o-expandable__expanded\n\n        \ndiv class=\nm-global-banner_head\n\n            \nspan class=\ncf-icon\n                         cf-icon-error-round\n                         m-global-banner_icon\n/span\n\n            This beta site is a work in progress.\n        \n/div\n\n        \u2026\n    \n/div\n\n\n/div\n\n{% endif %}\n\n\n\nDjango\n\u00b6\n\n\nIn Django templates (used in Satellite apps and the Wagtail admin), two template functions are provided \nflag_enabled\n and \nflag_disabled\n once the \nfeature_flags\n template tag library is loaded.\n\n\nflag_enabled 'MY_FLAG'\n will return \nTrue\n if the conditions under which \nMY_FLAG\n is enabled \nare\n met.\n\n\nflag_disabled 'MY_FLAG'\n will return \nTrue\n if the conditions under which \nMY_FLAG\n is enabled \nare not\n met.\n\n\nSee \nEnabling a flag\n below for more on flag conditions.\n\n\nThe \nBETA_NOTICE\n \nJinja2\n example above when implemented with Django templates would look like this:\n\n\n{% load feature_flags %}\n\n{% flag_enabled 'BETA_NOTICE' as beta_flag %}\n{% if beta_flag and show_banner %}\n\ndiv class=\nm-global-banner\n\n    \ndiv class=\nwrapper\n                wrapper__match-content\n                o-expandable\n                o-expandable__expanded\n\n        \ndiv class=\nm-global-banner_head\n\n            \nspan class=\ncf-icon\n                         cf-icon-error-round\n                         m-global-banner_icon\n/span\n\n            This beta site is a work in progress.\n        \n/div\n\n        \u2026\n    \n/div\n\n\n/div\n\n{% endif %}\n\n\n\nIn code\n\u00b6\n\n\nIn Python code three functions are available for checking feature flags, \nflag_state\n, \nflag_enabled\n, and \nflag_disabled\n. The Python API is slightly different from the \nJinja2\n or \nDjango template\n API, in that flag conditions can take more potential arguments than requests, and thus flags are more flexible when checked in Python (in and outside a request cycle).\n\n\nSee the \nWagtail Flags flag state API documentation for more\n.\n\n\nAdditionally two decorators, \nflag_check\n and \nflag_required\n, are provided for wrapping views (and another functions) in a feature flag check.  See the \nWagtail Flags flag decorators API documentation for more\n.\n\n\nIn URLs\n\u00b6\n\n\nThere are two ways to flag Django URL patterns in \nurls.py\n: with \nflagged_url()\n in place of \nurl()\n for a single pattern, or with the \nflagged_urls()\n context manager for multiple URLs.\n\n\nflagged_url(flag_name, regex, view, kwargs=None, name=None, state=True, fallback=None)\n works exactly like \nurl()\n except it takes a flag name as its first argument. If the flag's state matches the given \nstate\n, the URL pattern will be served from the given \nview\n; if not, and \nfallback\n is given, the \nfallback\n will be used.\n\n\nAn example is \nour \nWAGTAIL_ABOUT_US\n flag\n:\n\n\nflagged_url('WAGTAIL_ABOUT_US',\n            r'^about-us/$',\n            lambda req: ServeView.as_view()(req, req.path),\n            fallback=SheerTemplateView.as_view(\n                template_name='about-us/index.html'),\n            name='about-us'),\n\n\n\nIgnoring the \nview\n being a \nlambda\n for now (see \nFlagging Wagtail URLs below\n), this URL will be served via Wagtail if \nWAGTAIL_ABOUT_US\n's conditions are \nTrue\n, and from a \nTemplateView\n if its conditions are \nFalse\n.\n\n\nIf you need to flag multiple URLs with the same flag, you can use the \nflagged_urls()\n context manager.\n\n\nwith flagged_urls(flag_name, state=True, fallback=None) as url\n provides a context in which the returned \nurl()\n function can be used in place of the Django \nurl()\n function in patterns and those patterns will share the same feature flag, state, and fallback.\n\n\nAn example is \nour \nWAGTAIL_ASK_CFPB\n flag\n:\n\n\nwith flagged_urls('WAGTAIL_ASK_CFPB') as url:\n    ask_patterns = [\n        url(r'^(?i)ask-cfpb/([-\\w]{1,244})-(en)-(\\d{1,6})/?$',\n            view_answer,\n            name='ask-english-answer'),\n        url(r'^(?i)obtener-respuestas/([-\\w]{1,244})-(es)-(\\d{1,6})/?$',\n            view_answer,\n            name='ask-spanish-answer'),\n        \u2026\n    ]\n\nurlpatterns += ask_patterns\n\n\n\n\n\nWarning\n\n\nDo not attempt to use \nflag_check\n or any flag state-checking functions in \nurls.py\n. Because they will be evaluated on import of \nurls.py\n they will attempt to access the Django FlagState model before it is ready and will error.\n\n\n\n\nFlagging Wagtail URLs\n\u00b6\n\n\nWagtail views in \nflagged_url\n with a Django view as fallback (or vice-versa) can be a bit awkward. Django views are typically called with \nrequest\n as the first argument, and Wagtail's \nserve\n view takes both the request and the path. To get around this, in \nflagged_url\n we typically use a \nlambda\n for the view:\n\n\nlambda req: ServeView.as_view()(req, req.path)\n\n\n\nThis lambda takes the request and calls the \nWagtail-Sharing\n \nServeView\n (which we're using in place of \nwagtail.wagtailcore.views.serve\n).\n\n\nEnabling a flag\n\u00b6\n\n\nFeature flags are enabled based on a set of conditions that are given either in the Django settings files (in \ncfgov/cfgov/settings/\n) or in the Django or Wagtail admin. Multiple conditions can be given, both in settings and in the admin, and if any condition is satisfied a flag is enabled.\n\n\nA list of available conditions and how to use them is available in the Wagtail-Flags documentation\n.\n\n\nHard-coded conditions\n\u00b6\n\n\nConditions that are defined in the Django settings are hard-coded, and require a change to files in cfgov-refresh, a new tagged release, and new deployment to change. These conditions should be used for flags that are relatively long-lasting and that can require a round-trip through the release and deployment process to change.\n\n\nWhen \nadding a flag\n to the Django settings the flag's dictionary of conditions can contain a condition name and value that must be satisfied for the flag to be enabled. The nature of that value changes depending on the condition type. \nSee the Wagtail-Flags conditions documentation\n for more on individual conditions.\n\n\nThere is a simple \nboolean\n condition that is either \nTrue\n or \nFalse\n, and if it is \nTrue\n the flag is enabled and if it is \nFalse\n the flag is disabled. If we want to always turn the \nBETA_NOTICE\n flag on in settings with a \nboolean\n condition, that would look like this:\n\n\nFLAGS = {\n    # Beta banner, seen on beta.consumerfinance.gov\n    # When enabled, a banner appears across the top of the site proclaiming\n    # \nThis beta site is a work in progress.\n\n    'BETA_NOTICE': {\n        'boolean': True,\n    },\n}\n\n\n\nDatabase conditions\n\u00b6\n\n\nConditions that are managed via the Wagtail or Django admin are stored in the database. These conditions can be changed in real-time and do not require any code changes or release and deployment to change (presuming the code that uses the feature flag is in place).\n\n\nTo view, delete, and add database conditions, navigate to \"Settings \n Flags\" in the Wagtail admin.\n\n\n\n\nOnce in the flag settings, you'll have a list of all flags and their conditions..\n\n\n\n\nDatabase conditions can be deleted with the trash can button on the right.\n\n\nTo create a new database condition, select \"Add a condition\". As with \nhard-coded conditions\n, to create a database condition you must select which condition type you would like to use and give it a value that must be satisfied for the flag to be enabled.\n\n\n\n\nDatabase conditions can only be set for flags that exist in the Django settings.\n\n\nSatellite apps\n\u00b6\n\n\nFeature flags can be used in satellite apps in exactly the same way they are used in cfgov-refresh. An example is \nthe use of a feature flagged template choice in the complaintdatabase app\n.\n\n\nHygiene\n\u00b6\n\n\nFeature flags should be rare and ephemeral. Changes should be small and frequent, and not big-bang releases, and flags that are no longer used and their conditions should be cleaned up and removed from code and the database.", 
            "title": "Feature flags"
        }, 
        {
            "location": "/feature-flags/#feature-flags", 
            "text": "Feature flags are implemented using our  Wagtail-Flags  app. The  README  contains an overview and examples of how to use feature flags in Wagtail.  This document covers how to add and use feature flags with cfgov-refresh and the conventions we have around their use.   Adding a flag  Checking a flag  In templates  Jinja2  Django    In code  In URLs    Enabling a flag  Hard-coded conditions  Database conditions    Satellite apps  Hygiene", 
            "title": "Feature flags"
        }, 
        {
            "location": "/feature-flags/#adding-a-flag", 
            "text": "Feature flags are defined in code in the  cfgov/settings/base.py  file as part of the  FLAGS  setting. Each flag consists of a single string and a Python dictionary ( {} ) of its hard-coded conditions (see  Enabling a flag  below).  FLAGS = {\n    # Beta banner, seen on beta.consumerfinance.gov\n    # When enabled, a banner appears across the top of the site proclaiming\n    #  This beta site is a work in progress. \n    'BETA_NOTICE': {},\n}  By convention our flag names are all uppercase, with underscores instead of whitespace. A comment is expected above each flag with a short description fo what happens when it is enabled.", 
            "title": "Adding a flag"
        }, 
        {
            "location": "/feature-flags/#checking-a-flag", 
            "text": "Flags can be checked either in Python code or in Django or Jinja2 template files. See the full  Wagtail Flags API is documented   for more information.", 
            "title": "Checking a flag"
        }, 
        {
            "location": "/feature-flags/#in-templates", 
            "text": "", 
            "title": "In templates"
        }, 
        {
            "location": "/feature-flags/#jinja2", 
            "text": "Most of cfgov-refresh's templates are Jinja2. In these templates, two template functions are provided,  flag_enabled  and  flag_disabled . Each takes a flag name as its first argument and request` object as the second.  flag_enabled('MY_FLAG', request)  will return  True  if the conditions under which  MY_FLAG  is enabled  are  met.  flag_disabled('MY_FLAG', request)  will return  True  if the conditions under which  MY_FLAG  is enabled  are not  met.  See  Enabling a flag  below for more on flag conditions.  An example is  the  BETA_NOTICE flag  as implemented in  header.html :  {% if flag_enabled('BETA_NOTICE', request) and show_banner %} div class= m-global-banner \n     div class= wrapper\n                wrapper__match-content\n                o-expandable\n                o-expandable__expanded \n         div class= m-global-banner_head \n             span class= cf-icon\n                         cf-icon-error-round\n                         m-global-banner_icon /span \n            This beta site is a work in progress.\n         /div \n        \u2026\n     /div  /div \n{% endif %}", 
            "title": "Jinja2"
        }, 
        {
            "location": "/feature-flags/#django", 
            "text": "In Django templates (used in Satellite apps and the Wagtail admin), two template functions are provided  flag_enabled  and  flag_disabled  once the  feature_flags  template tag library is loaded.  flag_enabled 'MY_FLAG'  will return  True  if the conditions under which  MY_FLAG  is enabled  are  met.  flag_disabled 'MY_FLAG'  will return  True  if the conditions under which  MY_FLAG  is enabled  are not  met.  See  Enabling a flag  below for more on flag conditions.  The  BETA_NOTICE   Jinja2  example above when implemented with Django templates would look like this:  {% load feature_flags %}\n\n{% flag_enabled 'BETA_NOTICE' as beta_flag %}\n{% if beta_flag and show_banner %} div class= m-global-banner \n     div class= wrapper\n                wrapper__match-content\n                o-expandable\n                o-expandable__expanded \n         div class= m-global-banner_head \n             span class= cf-icon\n                         cf-icon-error-round\n                         m-global-banner_icon /span \n            This beta site is a work in progress.\n         /div \n        \u2026\n     /div  /div \n{% endif %}", 
            "title": "Django"
        }, 
        {
            "location": "/feature-flags/#in-code", 
            "text": "In Python code three functions are available for checking feature flags,  flag_state ,  flag_enabled , and  flag_disabled . The Python API is slightly different from the  Jinja2  or  Django template  API, in that flag conditions can take more potential arguments than requests, and thus flags are more flexible when checked in Python (in and outside a request cycle).  See the  Wagtail Flags flag state API documentation for more .  Additionally two decorators,  flag_check  and  flag_required , are provided for wrapping views (and another functions) in a feature flag check.  See the  Wagtail Flags flag decorators API documentation for more .", 
            "title": "In code"
        }, 
        {
            "location": "/feature-flags/#in-urls", 
            "text": "There are two ways to flag Django URL patterns in  urls.py : with  flagged_url()  in place of  url()  for a single pattern, or with the  flagged_urls()  context manager for multiple URLs.  flagged_url(flag_name, regex, view, kwargs=None, name=None, state=True, fallback=None)  works exactly like  url()  except it takes a flag name as its first argument. If the flag's state matches the given  state , the URL pattern will be served from the given  view ; if not, and  fallback  is given, the  fallback  will be used.  An example is  our  WAGTAIL_ABOUT_US  flag :  flagged_url('WAGTAIL_ABOUT_US',\n            r'^about-us/$',\n            lambda req: ServeView.as_view()(req, req.path),\n            fallback=SheerTemplateView.as_view(\n                template_name='about-us/index.html'),\n            name='about-us'),  Ignoring the  view  being a  lambda  for now (see  Flagging Wagtail URLs below ), this URL will be served via Wagtail if  WAGTAIL_ABOUT_US 's conditions are  True , and from a  TemplateView  if its conditions are  False .  If you need to flag multiple URLs with the same flag, you can use the  flagged_urls()  context manager.  with flagged_urls(flag_name, state=True, fallback=None) as url  provides a context in which the returned  url()  function can be used in place of the Django  url()  function in patterns and those patterns will share the same feature flag, state, and fallback.  An example is  our  WAGTAIL_ASK_CFPB  flag :  with flagged_urls('WAGTAIL_ASK_CFPB') as url:\n    ask_patterns = [\n        url(r'^(?i)ask-cfpb/([-\\w]{1,244})-(en)-(\\d{1,6})/?$',\n            view_answer,\n            name='ask-english-answer'),\n        url(r'^(?i)obtener-respuestas/([-\\w]{1,244})-(es)-(\\d{1,6})/?$',\n            view_answer,\n            name='ask-spanish-answer'),\n        \u2026\n    ]\n\nurlpatterns += ask_patterns   Warning  Do not attempt to use  flag_check  or any flag state-checking functions in  urls.py . Because they will be evaluated on import of  urls.py  they will attempt to access the Django FlagState model before it is ready and will error.", 
            "title": "In URLs"
        }, 
        {
            "location": "/feature-flags/#flagging-wagtail-urls", 
            "text": "Wagtail views in  flagged_url  with a Django view as fallback (or vice-versa) can be a bit awkward. Django views are typically called with  request  as the first argument, and Wagtail's  serve  view takes both the request and the path. To get around this, in  flagged_url  we typically use a  lambda  for the view:  lambda req: ServeView.as_view()(req, req.path)  This lambda takes the request and calls the  Wagtail-Sharing   ServeView  (which we're using in place of  wagtail.wagtailcore.views.serve ).", 
            "title": "Flagging Wagtail URLs"
        }, 
        {
            "location": "/feature-flags/#enabling-a-flag", 
            "text": "Feature flags are enabled based on a set of conditions that are given either in the Django settings files (in  cfgov/cfgov/settings/ ) or in the Django or Wagtail admin. Multiple conditions can be given, both in settings and in the admin, and if any condition is satisfied a flag is enabled.  A list of available conditions and how to use them is available in the Wagtail-Flags documentation .", 
            "title": "Enabling a flag"
        }, 
        {
            "location": "/feature-flags/#hard-coded-conditions", 
            "text": "Conditions that are defined in the Django settings are hard-coded, and require a change to files in cfgov-refresh, a new tagged release, and new deployment to change. These conditions should be used for flags that are relatively long-lasting and that can require a round-trip through the release and deployment process to change.  When  adding a flag  to the Django settings the flag's dictionary of conditions can contain a condition name and value that must be satisfied for the flag to be enabled. The nature of that value changes depending on the condition type.  See the Wagtail-Flags conditions documentation  for more on individual conditions.  There is a simple  boolean  condition that is either  True  or  False , and if it is  True  the flag is enabled and if it is  False  the flag is disabled. If we want to always turn the  BETA_NOTICE  flag on in settings with a  boolean  condition, that would look like this:  FLAGS = {\n    # Beta banner, seen on beta.consumerfinance.gov\n    # When enabled, a banner appears across the top of the site proclaiming\n    #  This beta site is a work in progress. \n    'BETA_NOTICE': {\n        'boolean': True,\n    },\n}", 
            "title": "Hard-coded conditions"
        }, 
        {
            "location": "/feature-flags/#database-conditions", 
            "text": "Conditions that are managed via the Wagtail or Django admin are stored in the database. These conditions can be changed in real-time and do not require any code changes or release and deployment to change (presuming the code that uses the feature flag is in place).  To view, delete, and add database conditions, navigate to \"Settings   Flags\" in the Wagtail admin.   Once in the flag settings, you'll have a list of all flags and their conditions..   Database conditions can be deleted with the trash can button on the right.  To create a new database condition, select \"Add a condition\". As with  hard-coded conditions , to create a database condition you must select which condition type you would like to use and give it a value that must be satisfied for the flag to be enabled.   Database conditions can only be set for flags that exist in the Django settings.", 
            "title": "Database conditions"
        }, 
        {
            "location": "/feature-flags/#satellite-apps", 
            "text": "Feature flags can be used in satellite apps in exactly the same way they are used in cfgov-refresh. An example is  the use of a feature flagged template choice in the complaintdatabase app .", 
            "title": "Satellite apps"
        }, 
        {
            "location": "/feature-flags/#hygiene", 
            "text": "Feature flags should be rare and ephemeral. Changes should be small and frequent, and not big-bang releases, and flags that are no longer used and their conditions should be cleaned up and removed from code and the database.", 
            "title": "Hygiene"
        }, 
        {
            "location": "/wagtail-migrations/", 
            "text": "Wagtail and Django data migrations\n\u00b6\n\n\nDjango data migrations with Wagtail can be challenging because programmatic editing of Wagtail pages \nis difficult\n, and pages have both revisions and StreamFields. This document is intended to describe ways we try to address these challenges in cfgov-refresh.\n\n\nMigrating StreamFields\n\u00b6\n\n\nStreamFields do not follow a fixed structure, rather they're a freeform sequences of blocks. Making a change to a StreamField involves both creating a \nDjango schema migration\n and a custom \nDjango data migration\n. The data migration needs to modify both the existing Wagtail pages that correspond to the changed model and all revisions of that page. It also needs to be able to manipulate the StreamField contents.\n\n\nTo this end, there are some utility functions in cfgov-refresh that make this easier. Using these utilities, a Django data migration that modifies a StreamField would use the following format:\n\n\nfrom django.db import migrations\n\nfrom v1.util.migrations import migrate_page_types_and_fields\n\n\ndef forward_mapper(page_or_revision, data):\n    data = dict(data)\n    # Manipulate the stream block data forwards\n    return data\n\n\ndef backward_mapper(page_or_revision, data):\n    data = dict(data)\n    # Manipulate the stream block data backwards\n    return data\n\n\ndef forwards(apps, schema_editor):\n    page_types_and_fields = [\n        ('myapp', 'MyPage', 'streamfield_name', 'streamblock_type'),\n    ]\n    migrate_page_types_and_fields(apps,\n                                  page_types_and_fields,\n                                  forward_mapper)\n\n\ndef backwards(apps, schema_editor):\n    page_types_and_fields = [\n        ('myapp', 'MyPage', 'streamfield_name', 'streamblock_type'),\n    ]\n    migrate_page_types_and_fields(apps,\n                                  page_types_and_fields,\n                                  backward_mapper)\n\n\nclass Migration(migrations.Migration):\n    dependencies = []\n    operations = [\n        migrations.RunPython(forwards, backwards),\n    ]\n\n\n\nUtility functions\n\u00b6\n\n\nThese functions are available in \nv1.util.migrations\n.\n\n\nmigrate_page_types_and_fields(apps, page_types_and_fields, mapper)\n\u00b6\n\n\nMigrate the fields of a wagtail page type using the given mapper function. page_types_and_fields should be a list of 4-tuples providing ('app', 'PageType', 'field_name', 'block type').\n\n\nThe mapper function should take \npage_or_revision\n and the stream block value.\n\n\nmigrate_stream_field(page_or_revision, field_name, block_type, mapper)\n\u00b6\n\n\nMigrate a block of the type within a StreamField of the name belonging to the page or revision using the mapper function.\n\n\nThe mapper function should take \npage_or_revision\n and the stream block value.\n\n\nget_stream_data(page_or_revision, field_name)\n\u00b6\n\n\nGet the stream field data for a given field name on a page or a revision.\n\n\nThis function will return a list of \ndict\n-like objects containing the blocks within the given StreamField.\n\n\nset_stream_data(page_or_revision, field_name, stream_data, commit=True)\n\u00b6\n\n\nSet the stream field data for a given field name on a page or a revision. If commit is True (default) \nsave()\n is called on the \npage_or_revision\n object.\n\n\nstream_data\n must be a list of \ndict\n-like objects containing the blocks within the given StreamField.", 
            "title": "Wagtail and Django migrations"
        }, 
        {
            "location": "/wagtail-migrations/#wagtail-and-django-data-migrations", 
            "text": "Django data migrations with Wagtail can be challenging because programmatic editing of Wagtail pages  is difficult , and pages have both revisions and StreamFields. This document is intended to describe ways we try to address these challenges in cfgov-refresh.", 
            "title": "Wagtail and Django data migrations"
        }, 
        {
            "location": "/wagtail-migrations/#migrating-streamfields", 
            "text": "StreamFields do not follow a fixed structure, rather they're a freeform sequences of blocks. Making a change to a StreamField involves both creating a  Django schema migration  and a custom  Django data migration . The data migration needs to modify both the existing Wagtail pages that correspond to the changed model and all revisions of that page. It also needs to be able to manipulate the StreamField contents.  To this end, there are some utility functions in cfgov-refresh that make this easier. Using these utilities, a Django data migration that modifies a StreamField would use the following format:  from django.db import migrations\n\nfrom v1.util.migrations import migrate_page_types_and_fields\n\n\ndef forward_mapper(page_or_revision, data):\n    data = dict(data)\n    # Manipulate the stream block data forwards\n    return data\n\n\ndef backward_mapper(page_or_revision, data):\n    data = dict(data)\n    # Manipulate the stream block data backwards\n    return data\n\n\ndef forwards(apps, schema_editor):\n    page_types_and_fields = [\n        ('myapp', 'MyPage', 'streamfield_name', 'streamblock_type'),\n    ]\n    migrate_page_types_and_fields(apps,\n                                  page_types_and_fields,\n                                  forward_mapper)\n\n\ndef backwards(apps, schema_editor):\n    page_types_and_fields = [\n        ('myapp', 'MyPage', 'streamfield_name', 'streamblock_type'),\n    ]\n    migrate_page_types_and_fields(apps,\n                                  page_types_and_fields,\n                                  backward_mapper)\n\n\nclass Migration(migrations.Migration):\n    dependencies = []\n    operations = [\n        migrations.RunPython(forwards, backwards),\n    ]", 
            "title": "Migrating StreamFields"
        }, 
        {
            "location": "/wagtail-migrations/#utility-functions", 
            "text": "These functions are available in  v1.util.migrations .", 
            "title": "Utility functions"
        }, 
        {
            "location": "/wagtail-migrations/#migrate_page_types_and_fieldsapps-page_types_and_fields-mapper", 
            "text": "Migrate the fields of a wagtail page type using the given mapper function. page_types_and_fields should be a list of 4-tuples providing ('app', 'PageType', 'field_name', 'block type').  The mapper function should take  page_or_revision  and the stream block value.", 
            "title": "migrate_page_types_and_fields(apps, page_types_and_fields, mapper)"
        }, 
        {
            "location": "/wagtail-migrations/#migrate_stream_fieldpage_or_revision-field_name-block_type-mapper", 
            "text": "Migrate a block of the type within a StreamField of the name belonging to the page or revision using the mapper function.  The mapper function should take  page_or_revision  and the stream block value.", 
            "title": "migrate_stream_field(page_or_revision, field_name, block_type, mapper)"
        }, 
        {
            "location": "/wagtail-migrations/#get_stream_datapage_or_revision-field_name", 
            "text": "Get the stream field data for a given field name on a page or a revision.  This function will return a list of  dict -like objects containing the blocks within the given StreamField.", 
            "title": "get_stream_data(page_or_revision, field_name)"
        }, 
        {
            "location": "/wagtail-migrations/#set_stream_datapage_or_revision-field_name-stream_data-committrue", 
            "text": "Set the stream field data for a given field name on a page or a revision. If commit is True (default)  save()  is called on the  page_or_revision  object.  stream_data  must be a list of  dict -like objects containing the blocks within the given StreamField.", 
            "title": "set_stream_data(page_or_revision, field_name, stream_data, commit=True)"
        }, 
        {
            "location": "/django-to-wagtail/", 
            "text": "Wagtail pages vs. Django views\n\u00b6\n\n\nRather than using \u201cclassic\u201d Django views added to urls.py, when feasible an app should provide a singleton Wagtail Page. This will allow site editors to drop that page anywhere in the site\u2019s URL structure that they wish. A Wagtail Page subclass can do anything a Django view can \nwhen overriding the serve method\n.\n\n\nfrom django.http import HttpResponse\nfrom wagtail.wagtailcore.models import Page\n\nclass HelloWorldPage(Page):\n    def serve(self, request):\n        return HttpResponse(\nHello World\n)\n\n\n\nBy working with the Wagtail CMS, we also get some of the benefits of feature flags for free.", 
            "title": "Wagtail Pages vs Django views"
        }, 
        {
            "location": "/django-to-wagtail/#wagtail-pages-vs-django-views", 
            "text": "Rather than using \u201cclassic\u201d Django views added to urls.py, when feasible an app should provide a singleton Wagtail Page. This will allow site editors to drop that page anywhere in the site\u2019s URL structure that they wish. A Wagtail Page subclass can do anything a Django view can  when overriding the serve method .  from django.http import HttpResponse\nfrom wagtail.wagtailcore.models import Page\n\nclass HelloWorldPage(Page):\n    def serve(self, request):\n        return HttpResponse( Hello World )  By working with the Wagtail CMS, we also get some of the benefits of feature flags for free.", 
            "title": "Wagtail pages vs. Django views"
        }, 
        {
            "location": "/forms-in-wagtail/", 
            "text": "Including forms into Wagtail page context\n\u00b6\n\n\nWagtail provides a FormBuilder module, but it cannot be used with subclasses of Page, like our CFGOVPage. For our purposes there is \nAbstractFormBlock\n, a subclass of StructBlock that implements methods to process a request. If a developer wishes to add a module that includes a form, they only need to follow a few steps in order to get it handled properly:\n\n\n\n\nCreate the form.\n\n\nCreate handler class that implements a method named \nprocess\n.\n\n\nThe process method should take in a boolean parameter named \nis_submitted\n that flags whether or not that particular module has been the source of the request.\n\n\nThe process method should return a dictionary that will be included in the context of the page and a JSONResponse for AJAX requests. If a context is returned, this is where the form would go.\n\n\n\n\n\n\nCreate a subclass of \nAbstractFormBlock\n with any other blocks that are required.\n\n\nAdd the path to the handler class to the block class' Meta handler attribute.\n\n\n\n\n\n\nCreate a template in which to render the form.\n\n\n\n\nHere's an example of a form's block class:\n\n...\n\nclass FormBlock(AbstractFormBlock):\n    heading = blocks.CharBlock()\n\n    class Meta:\n        handler = 'app_name.handlers.handler_class'\n        # defaults\n        method = 'POST'\n        icon = 'form'\n\n...\n\n\nAnd an example of a handler class:\n\n...\n\nclass ConferenceRegistrationHandler(Handler):\n    def process(self, is_submitted):\n        if is_submitted:\n            form = Form(self.request.POST)\n            if form.is_valid():\n                return success\n            else:\n                return fail\n\n        return {'form': Form()}\n\n...", 
            "title": "Forms in Wagtail page context"
        }, 
        {
            "location": "/forms-in-wagtail/#including-forms-into-wagtail-page-context", 
            "text": "Wagtail provides a FormBuilder module, but it cannot be used with subclasses of Page, like our CFGOVPage. For our purposes there is  AbstractFormBlock , a subclass of StructBlock that implements methods to process a request. If a developer wishes to add a module that includes a form, they only need to follow a few steps in order to get it handled properly:   Create the form.  Create handler class that implements a method named  process .  The process method should take in a boolean parameter named  is_submitted  that flags whether or not that particular module has been the source of the request.  The process method should return a dictionary that will be included in the context of the page and a JSONResponse for AJAX requests. If a context is returned, this is where the form would go.    Create a subclass of  AbstractFormBlock  with any other blocks that are required.  Add the path to the handler class to the block class' Meta handler attribute.    Create a template in which to render the form.   Here's an example of a form's block class: ...\n\nclass FormBlock(AbstractFormBlock):\n    heading = blocks.CharBlock()\n\n    class Meta:\n        handler = 'app_name.handlers.handler_class'\n        # defaults\n        method = 'POST'\n        icon = 'form'\n\n...  And an example of a handler class: ...\n\nclass ConferenceRegistrationHandler(Handler):\n    def process(self, is_submitted):\n        if is_submitted:\n            form = Form(self.request.POST)\n            if form.is_valid():\n                return success\n            else:\n                return fail\n\n        return {'form': Form()}\n\n...", 
            "title": "Including forms into Wagtail page context"
        }, 
        {
            "location": "/testing-be/", 
            "text": "Backend testing\n\u00b6\n\n\nDjango and Python unit tests\n\u00b6\n\n\nTo run the the full suite of unit tests using Tox, cd to the project root and\nthen run:\n\n\ntox\n\n\n\nBy default this uses a local SQLite database for tests. To override this, you\ncan set the \nDATABASE_URL\n environment variable to a database connection\nsring as supported by \ndj-database-url\n.\n\n\nIf you haven't changed any installed packages and you don't need to test \nall migrations, you can run a much faster Python code test using:\n\ntox -e fast\n\n\nTo see Python code coverage information, run\n\n./show_coverage.sh\n\n\nSource code linting\n\u00b6\n\n\nWe use the \nflake8\n and \nisort\n tools to ensure compliance with \n\nPEP8 style guide\n and the \n\nDjango coding style guidelines\n. \nWe do make two exceptions to PEP8 that are ignored in our flake8 \nconfiguration:\n\n\n\n\nE731\n, we allow assignment of lambda expressions\n\n\nW503\n, we allow line breaks after binary operators\n\n\n\n\nBoth \nflake8\n and \nisort\n can be run using the Tox \nlint\n environment:\n\n\ntox -e lint\n\n\n\nThis will run \nisort\n in check-only mode and it will print diffs for imports \nthat need to be fixed. To automatically fix import sort issues, run:\n\n\nisort --recursive cfgov/\n\n\n\nFrom the root of \ncfgov-refresh\n.\n\n\nPython 3\n\u00b6\n\n\nBoth unit tests and linting can be run with Python 3 to aid in our transition. To run with all Django migrations, \n\n\ntox -e py36\n\n\n\nor without Django migrations,\n\n\ntox -e fast-py3\n\n\n\nExisting unit tests that run on code that has not been made compatible with Python 3 may error or fail, but it is possible to run new tests individually with\n\n\ntox -e fast-py3 package.tests.test_my_code\n\n\n\nTo run both \nflake8\n and \nisort\n with Python 3, run\n\n\ntox -e lint-py3\n\n\n\nGovDelivery\n\u00b6\n\n\nIf you write Python code that interacts with the GovDelivery subscription API, you can use the functionality provided in \ncore.govdelivery.MockGovDelivery\n as a mock interface to avoid the use of \npatch\n in unit tests.\n\n\nThis object behaves similarly to the real \ngovdelivery.api.GovDelivery\n class in that it handles all requests and returns a valid (200) \nrequests.Response\n instance.\n\n\nConveniently for unit testing, all calls are stored in a class-level list that can be retrieved at \nMockGovDelivery.calls\n. This allows for testing of code that interacts with GovDelivery by checking the contents of this list to ensure that the right methods were called.\n\n\nThis pattern is modeled after Django's \ndjango.core.mail.outbox\n which provides similar functionality for testing sending of emails.\n\n\nThe related classes \nExceptionMockGovDelivery\n and \nServerErrorMockGovDelivery\n can similarly be used in unit tests to test for cases where a call to the GovDelivery API raises an exception and returns an HTTP status code of 500, respectively.", 
            "title": "Testing"
        }, 
        {
            "location": "/testing-be/#backend-testing", 
            "text": "", 
            "title": "Backend testing"
        }, 
        {
            "location": "/testing-be/#django-and-python-unit-tests", 
            "text": "To run the the full suite of unit tests using Tox, cd to the project root and\nthen run:  tox  By default this uses a local SQLite database for tests. To override this, you\ncan set the  DATABASE_URL  environment variable to a database connection\nsring as supported by  dj-database-url .  If you haven't changed any installed packages and you don't need to test \nall migrations, you can run a much faster Python code test using: tox -e fast  To see Python code coverage information, run ./show_coverage.sh", 
            "title": "Django and Python unit tests"
        }, 
        {
            "location": "/testing-be/#source-code-linting", 
            "text": "We use the  flake8  and  isort  tools to ensure compliance with  PEP8 style guide  and the  Django coding style guidelines . \nWe do make two exceptions to PEP8 that are ignored in our flake8 \nconfiguration:   E731 , we allow assignment of lambda expressions  W503 , we allow line breaks after binary operators   Both  flake8  and  isort  can be run using the Tox  lint  environment:  tox -e lint  This will run  isort  in check-only mode and it will print diffs for imports \nthat need to be fixed. To automatically fix import sort issues, run:  isort --recursive cfgov/  From the root of  cfgov-refresh .", 
            "title": "Source code linting"
        }, 
        {
            "location": "/testing-be/#python-3", 
            "text": "Both unit tests and linting can be run with Python 3 to aid in our transition. To run with all Django migrations,   tox -e py36  or without Django migrations,  tox -e fast-py3  Existing unit tests that run on code that has not been made compatible with Python 3 may error or fail, but it is possible to run new tests individually with  tox -e fast-py3 package.tests.test_my_code  To run both  flake8  and  isort  with Python 3, run  tox -e lint-py3", 
            "title": "Python 3"
        }, 
        {
            "location": "/testing-be/#govdelivery", 
            "text": "If you write Python code that interacts with the GovDelivery subscription API, you can use the functionality provided in  core.govdelivery.MockGovDelivery  as a mock interface to avoid the use of  patch  in unit tests.  This object behaves similarly to the real  govdelivery.api.GovDelivery  class in that it handles all requests and returns a valid (200)  requests.Response  instance.  Conveniently for unit testing, all calls are stored in a class-level list that can be retrieved at  MockGovDelivery.calls . This allows for testing of code that interacts with GovDelivery by checking the contents of this list to ensure that the right methods were called.  This pattern is modeled after Django's  django.core.mail.outbox  which provides similar functionality for testing sending of emails.  The related classes  ExceptionMockGovDelivery  and  ServerErrorMockGovDelivery  can similarly be used in unit tests to test for cases where a call to the GovDelivery API raises an exception and returns an HTTP status code of 500, respectively.", 
            "title": "GovDelivery"
        }, 
        {
            "location": "/translation/", 
            "text": "Translation\n\u00b6\n\n\nAs cfgov-refresh is a Django project, the \nDjango translation documentation is a good place to start\n. What follows is a brief introduction to translations with the particular tools cfgov-refresh uses (like Jinja2 templates) and the conventions we use.\n\n\nOverview\n\u00b6\n\n\nTranslation is generally handled by one form or another of \ngettext\n. By convention, this is usually performed in code by wrapping a string to be translated in a function that is either named or aliased with an underscore. For example:\n\n\n_(\nThis is a translatable string.\n)\n\n\n\nThese strings are collected into portable object (\n.po\n) files for each supported language. These files map the original string (\nmsgid\n) to a matching translated string (\nmsgstr\n). For example:\n\n\nmsgid \nThis is a translatable string.\n\nmsgstr \nEsta es una cadena traducible.\n\n\n\nThese portable object files are compiled into machine object files (\n.mo\n) that the translation system uses when looking up the original string.\n\n\nBy convention the \n.po\n and \n.mo\n files live inside a \nlocale/[LANGUAGE]/LC_MESSAGES/\n folder structure, for example, \ncfgov/locale/es/LC_MESSAGES/django.po\n for the Spanish language portable object file for all of our cfgov-refresh messages.\n\n\nHow to translate text in cfgov-refresh\n\u00b6\n\n\nThis brief howto will guide you through adding translatable text to cfgov-refresh.\n\n\n1. Add the translation function around the string\n\u00b6\n\n\nIn Jinja2 templates:\n\n\n{{ _('Hello World!') }}\n\n\n\nIn Django templates:\n\n\n{% load i18n %}\n\n{% trans \nHello World!\n %}\n\n\n\nIn Python code:\n\n\nfrom django.utils.translation import ugettext as _\n\nmystring = _('Hello World!')\n\n\n\nThe string in the call to the translation function will be the \nmsgid\n in the portable object file below.\n\n\n2. Run the \nmakemessages\n management command to add the string to the portable object file\n\u00b6\n\n\nThe \nmakemessages\n management command will look through all Python, Django, and Jinja2 template files to find strings that are wrapped in a translation function call and add them to the portable object file for a particular language. The language is specified with \n-l\n. The command also must be called from the root of the Django app tree, \nnot\n the project root.\n\n\nTo generate or update the portable object file for Spanish:\n\n\ncd cfgov\ndjango-admin.py makemessages -l es\n\n\n\n3. Edit the portable object file to add a translation for the string\n\u00b6\n\n\nThe portable object files are stored in \ncfgov/locale/[LANGUAGE]/LC_MESSAGES/\n. For the Spanish portable object file, edit \ncfgov/locale/es/LC_MESSAGES/django.po\n and add the Spanish translation as the \nmsgstr\n for your new \nmsgid\n\n\nmsgid \nHello World!\n\nmsgstr \nHola Mundo!\n\n\n\n4. Run the \ncompilemessages\n management command to compile the machine object file\n\u00b6\n\n\ncd cfgov\ndjango-admin.py compilemessages\n\n\n\nWagtail Considerations\n\u00b6\n\n\nAll of our Wagtail pages include a language-selection dropdown under its Configuration tab:\n\n\n\n\nThe selected language will force translation of all translatable strings in templates and code for that page.", 
            "title": "Translation"
        }, 
        {
            "location": "/translation/#translation", 
            "text": "As cfgov-refresh is a Django project, the  Django translation documentation is a good place to start . What follows is a brief introduction to translations with the particular tools cfgov-refresh uses (like Jinja2 templates) and the conventions we use.", 
            "title": "Translation"
        }, 
        {
            "location": "/translation/#overview", 
            "text": "Translation is generally handled by one form or another of  gettext . By convention, this is usually performed in code by wrapping a string to be translated in a function that is either named or aliased with an underscore. For example:  _( This is a translatable string. )  These strings are collected into portable object ( .po ) files for each supported language. These files map the original string ( msgid ) to a matching translated string ( msgstr ). For example:  msgid  This is a translatable string. \nmsgstr  Esta es una cadena traducible.  These portable object files are compiled into machine object files ( .mo ) that the translation system uses when looking up the original string.  By convention the  .po  and  .mo  files live inside a  locale/[LANGUAGE]/LC_MESSAGES/  folder structure, for example,  cfgov/locale/es/LC_MESSAGES/django.po  for the Spanish language portable object file for all of our cfgov-refresh messages.", 
            "title": "Overview"
        }, 
        {
            "location": "/translation/#how-to-translate-text-in-cfgov-refresh", 
            "text": "This brief howto will guide you through adding translatable text to cfgov-refresh.", 
            "title": "How to translate text in cfgov-refresh"
        }, 
        {
            "location": "/translation/#1-add-the-translation-function-around-the-string", 
            "text": "In Jinja2 templates:  {{ _('Hello World!') }}  In Django templates:  {% load i18n %}\n\n{% trans  Hello World!  %}  In Python code:  from django.utils.translation import ugettext as _\n\nmystring = _('Hello World!')  The string in the call to the translation function will be the  msgid  in the portable object file below.", 
            "title": "1. Add the translation function around the string"
        }, 
        {
            "location": "/translation/#2-run-the-makemessages-management-command-to-add-the-string-to-the-portable-object-file", 
            "text": "The  makemessages  management command will look through all Python, Django, and Jinja2 template files to find strings that are wrapped in a translation function call and add them to the portable object file for a particular language. The language is specified with  -l . The command also must be called from the root of the Django app tree,  not  the project root.  To generate or update the portable object file for Spanish:  cd cfgov\ndjango-admin.py makemessages -l es", 
            "title": "2. Run the makemessages management command to add the string to the portable object file"
        }, 
        {
            "location": "/translation/#3-edit-the-portable-object-file-to-add-a-translation-for-the-string", 
            "text": "The portable object files are stored in  cfgov/locale/[LANGUAGE]/LC_MESSAGES/ . For the Spanish portable object file, edit  cfgov/locale/es/LC_MESSAGES/django.po  and add the Spanish translation as the  msgstr  for your new  msgid  msgid  Hello World! \nmsgstr  Hola Mundo!", 
            "title": "3. Edit the portable object file to add a translation for the string"
        }, 
        {
            "location": "/translation/#4-run-the-compilemessages-management-command-to-compile-the-machine-object-file", 
            "text": "cd cfgov\ndjango-admin.py compilemessages", 
            "title": "4. Run the compilemessages management command to compile the machine object file"
        }, 
        {
            "location": "/translation/#wagtail-considerations", 
            "text": "All of our Wagtail pages include a language-selection dropdown under its Configuration tab:   The selected language will force translation of all translatable strings in templates and code for that page.", 
            "title": "Wagtail Considerations"
        }, 
        {
            "location": "/caching/", 
            "text": "Caching\n\u00b6\n\n\nAkamai\n\u00b6\n\n\nWe use \nAkamai\n, a content delivery network, to cache the entirety of \nwww.consumerfinance.gov\n (but not our development servers). We invalidate any given page in Wagtail when it is published or unpublished (by hooking up the custom class \nAkamaiBackend\n to \nWagtail's frontend cache invalidator\n. By default, we clear the Akamai cache any time we deploy.\n\n\nThere are certain pages that do not live in Wagtail or are impacted by changes on another page (imagine our \nnewsroom page\n that lists titles of other pages) or another process (imagine data from Socrata gets updated) and thus will display outdated content until the page's time to live (TTL) has expired, a deploy has happened, or if someone manually invalidates that page. Our default TTL is 24 hours.\n\n\nDjango caching\n\u00b6\n\n\nStarting in December 2017, we use \ntemplate fragment caching\n to cache all or part of a template.  It is enabled on our \"post previews\", snippets of a page that we display on results of filterable pages (e.g. \nour blog page\n \n \nresearch \n reports\n).\n\n\nIt can easily be enabled on other templates. See \nthis PR\n as an example of the code that would need to be introduced to cache a new fragment.\n\n\nWhen a page gets published, it will update the post preview cache for that particular page.  However, if there are code changes that impact the page's content, or the post preview template itself gets updated, the entire post preview cache will need to be manually cleared. Clearing this particular cache could be an option when deploying, as it is with Akamai, but should not be a default since most deploys wouldn't impact the code in question.  Currently, the manual way to do this would be to run the following from a production server's django shell:\n\n\nfrom django.core.cache import caches\n\ncaches['post_preview'].clear()\n\n\n\nTo run the application locally with caching for post previews enabled, run \nENABLE_POST_PREVIEW_CACHE=1 ./runserver.sh\n\nAlternatively, add this variable to your \n.env\n if you generally want it enabled locally.\n\n\nDue to the impossibility/difficulty/complexity of caching individual Wagtail blocks (they are not serializable) and invalidating content that does not have some type of \npost_save\n hook (e.g. Taggit models), we have started with caching segments that are tied to a Wagtail page (which can be easily invalidated using the \npage_published\n Wagtail signal), hence the post previews. With more research or improvements to these third-party libraries, it is possible we could expand Django-level caching to more content.", 
            "title": "Caching"
        }, 
        {
            "location": "/caching/#caching", 
            "text": "", 
            "title": "Caching"
        }, 
        {
            "location": "/caching/#akamai", 
            "text": "We use  Akamai , a content delivery network, to cache the entirety of  www.consumerfinance.gov  (but not our development servers). We invalidate any given page in Wagtail when it is published or unpublished (by hooking up the custom class  AkamaiBackend  to  Wagtail's frontend cache invalidator . By default, we clear the Akamai cache any time we deploy.  There are certain pages that do not live in Wagtail or are impacted by changes on another page (imagine our  newsroom page  that lists titles of other pages) or another process (imagine data from Socrata gets updated) and thus will display outdated content until the page's time to live (TTL) has expired, a deploy has happened, or if someone manually invalidates that page. Our default TTL is 24 hours.", 
            "title": "Akamai"
        }, 
        {
            "location": "/caching/#django-caching", 
            "text": "Starting in December 2017, we use  template fragment caching  to cache all or part of a template.  It is enabled on our \"post previews\", snippets of a page that we display on results of filterable pages (e.g.  our blog page     research   reports ).  It can easily be enabled on other templates. See  this PR  as an example of the code that would need to be introduced to cache a new fragment.  When a page gets published, it will update the post preview cache for that particular page.  However, if there are code changes that impact the page's content, or the post preview template itself gets updated, the entire post preview cache will need to be manually cleared. Clearing this particular cache could be an option when deploying, as it is with Akamai, but should not be a default since most deploys wouldn't impact the code in question.  Currently, the manual way to do this would be to run the following from a production server's django shell:  from django.core.cache import caches\n\ncaches['post_preview'].clear()  To run the application locally with caching for post previews enabled, run  ENABLE_POST_PREVIEW_CACHE=1 ./runserver.sh \nAlternatively, add this variable to your  .env  if you generally want it enabled locally.  Due to the impossibility/difficulty/complexity of caching individual Wagtail blocks (they are not serializable) and invalidating content that does not have some type of  post_save  hook (e.g. Taggit models), we have started with caching segments that are tied to a Wagtail page (which can be easily invalidated using the  page_published  Wagtail signal), hence the post previews. With more research or improvements to these third-party libraries, it is possible we could expand Django-level caching to more content.", 
            "title": "Django caching"
        }, 
        {
            "location": "/atomic-structure/", 
            "text": "Notes on Atomic Design\n\u00b6\n\n\nCheck out \nDon't Build Pages, Build Modules\n.\nIt encompasses exactly what we are trying to achieve by building components\nusing atomic design.\nIt's important to note that our front-end atomic architecture is still evolving.\n\n\nOur components are broken down into templates, organisms, molecules, and atoms.\nWe opted not to use the page component, although it exists in atomic design.\nOur components are composed of HTML, CSS, and JS (JavaScript).\nIf a component doesn\u2019t have user interactions or require styling,\nthen it won\u2019t have an associated JS and/or CSS file.\n\n\nWe compose our atomic components as follows:\n\n\nAtoms\n\u00b6\n\n\nPrefixed with \u201ca-\u201d in CSS, JavaScript, and HTML files.\n\n\nHTML\n\u00b6\n\n\ndiv class=\na-overlay u-hidden\n/div\n\n\n\nCSS\n\u00b6\n\n\n .a-overlay {\n    // Only show overlay at mobile/tablet size.\n    .respond-to-max( @bp-sm-max, {\n        height: 100%;\n        width: 100%;\n \u2026\n\n\n\nMolecules\n\u00b6\n\n\nPrefixed with \u201cm-\u201d in CSS, JavaScript, and HTML files.\n\n\nHTML\n\u00b6\n\n\ndiv class=\nm-notification\n            m-notification__visible\n            m-notification__error\n\n     data-js-hook=\nstate_atomic_init\n\n    {{ svg_icon('error') }}\n    \ndiv class=\nm-notification_content\n role=\nalert\n\n        \ndiv class=\nh4 m-notification_message\nPage not found.\n/div\n\n    \n/div\n\n\n/div\n\n\n\nCSS\n\u00b6\n\n\n.m-notification {\n    display: none;\n    position: relative;\n    padding: @notification-padding__px;\n    \u2026\n\n\n\nJavaScript\n\u00b6\n\n\nfunction Notification( element ) {\n   const BASE_CLASS = 'm-notification';\n\n   // Constants for the state of this Notification.\n   const SUCCESS = 'success';\n   const WARNING = 'warning';\n   const ERROR = 'error';\n\n   // Constants for the Notification modifiers.\n   const MODIFIER_VISIBLE = BASE_CLASS + '__visible';\n   const _dom = atomicHelpers.checkDom( element, BASE_CLASS );\n   const _contentDom = _dom.querySelector( '.' + BASE_CLASS + '_content' );\n   \u2026\n\n\n\nThe notification molecule can be instantiated with the following code:\n\n\nconst notification = new Notification( _dom );\nnotification.init();\n\n\n\nOrganisms\n\u00b6\n\n\nPrefixed with \u201co-\u201d in CSS, JavaScript, and HTML.\n\n\nHTML\n\u00b6\n\n\ndiv class=\no-expandable\n            o-expandable__borders\n            o-expandable__midtone\n            o-expandable__expanded\n\n     data-js-hook=\nstate_atomic_init\n\n    \nbutton class=\no-expandable_target\n aria-pressed=\ntrue\n\n        \ndiv class=\no-expandable_header\n\n        \u2026\n\n\n\nJavaScript:\n\n\n function Expandable( element ) {\n  const BASE_CLASS = 'o-expandable';\n\n  // Bitwise flags for the state of this Expandable.\n  const COLLAPSED = 0;\n  const COLLAPSING = 1;\n  const EXPANDING = 2;\n  const EXPANDED = 3;\n\n  // The Expandable element will directly be the Expandable\n  // when used in an ExpandableGroup, otherwise it can be the parent container.\n  const _dom = atomicHelpers.checkDom( element, BASE_CLASS );\n  const _target = _dom.querySelector( '.' + BASE_CLASS + '_target' );\n  const _content = _dom.querySelector( '.' + BASE_CLASS + '_content' );\n  \u2026\n\n\n\nThe Expandable organism can be instantiated with the following code:\n\n\nconst expandable = new Expandable( _dom.querySelector( '.o-expandable' ) );\nexpandable.init( _expandable.EXPANDED );\n\n\n\nor\n\n\nconst atomicHelpers = require( '../../modules/util/atomic-helpers' );\nconst Expandable = require( '../../organisms/Expandable' );\natomicHelpers.instantiateAll( '.o-expandable', Expandable );\n\n\n\nTemplates\n\u00b6\n\n\nPrefixed with \u201ct-\u201d in CSS, JavaScript, and HTML. \nView all available templates\n that can be extended or reused to create pages.\n\n\nCSS\n\u00b6\n\n\n.t-careers {\n    \n_social .m-social-media {\n        float: right;\n    }\n    \u2026\n\n\n\nFolder structure\n\u00b6\n\n\nOur atomic components are separated and named based on asset type. HTML, CSS, and JavaScript for each component are in separate directories.\n\n\nCurrent structure\n\u00b6\n\n\nHTML\n\u00b6\n\n\ncfgov-refresh/cfgov/jinja2/v1/_includes/atoms/\ncfgov-refresh/cfgov/jinja2/v1/_includes/molecules/\ncfgov-refresh/cfgov/jinja2/v1/_includes/organisms/\n\n\n\nCSS\n\u00b6\n\n\ncfgov-refresh/cfgov/unprocessed/css/atoms/\ncfgov-refresh/cfgov/unprocessed/css/molecules/\ncfgov-refresh/cfgov/unprocessed/css/organisms/\n\n\n\nJavaScript\n\u00b6\n\n\ncfgov-refresh/cfgov/unprocessed/js/atoms/\ncfgov-refresh/cfgov/unprocessed/js/molecules/\ncfgov-refresh/cfgov/unprocessed/js/organisms/\n\n\n\nTest\n\u00b6\n\n\ncfgov-refresh/test/unit_tests/atoms/\ncfgov-refresh/test/unit_tests/molecules/\ncfgov-refresh/test/unit_tests/organisms/\n\n\n\nJavaScript architecture\n\u00b6\n\n\nJavaScript components are built to be rendered on the server and then enhanced via JavaScript on the client. The basic interface for the components is as follows:\n\n\nfunction AtomicComponent( domElement ) {\n    // Ensure the passed in Element is in the DOM.\n    // Query and store references to sub-elements.\n    // Instantiate child atomic components.\n    // Bind necessary events for referenced DOM elements.\n    // Perform other initialization related tasks.\n    this.init = function init(){}\n\n    // General teardown function\n    // We don't remove the element from the DOM so\n    // we need to unbind the events.\n    this.destroy = function destroy(){}\n}\n\n\n\nWe generally favor composition over inheritance.\nYou can get more information by reading the following:\n\n\nArticles\n\u00b6\n\n\nA Simple Challenge to Classical Inheritance Fans\n\n\nComposition over Inheritance (Youtube)\n\n\nComponent build pipeline\n\u00b6\n\n\nGulp\n\u00b6\n\n\nGulp is used as a task automation tool. Tasks include compiling CSS, creating a standard webpack workflow for bundling scripts, minifying code, linting, image optimizing, running unit tests, and \nmore\n.\n\n\nWebpack\n\u00b6\n\n\nWepback is used as a module bundler although it's capable of more.\nWe create page, global, and atomic specific bundles.\nThe configuration for the bundles is contained in config/webpack-config.js.\nAn explanation for the usage of each bundle is contained in scripts.js.\n\n\nRoutes\n\u00b6\n\n\nRoutes are used to serve JavaScript bundles to the browser based\non the requested URL or Wagtail page Media property.\nThis happens via code contained in \nbase.html\n. This file serves as the base HTML template for serving up assets and content. \nView base.html on Github\n.\n\n\nWagtail page media property\n\u00b6\n\n\nEach atomic component has a media property that list the JavaScript files\nthat should be rendered via base.html.\nWhen a page is requested via the browser, code contained in base.html will\nloop all atomic components for the requested page and render\nthe appropriate atomic JavaScript bundles.\n\n\nHere is an example of the media property on a component from the \nEmail signup organism\n:\n\n\nclass Media:\n    js = ['email-signup.js']\n\n\n\nThis will load the \nemail-signup.js\n script on any page that includes the Email Signup organism in its template.", 
            "title": "Atomic structure and design"
        }, 
        {
            "location": "/atomic-structure/#notes-on-atomic-design", 
            "text": "Check out  Don't Build Pages, Build Modules .\nIt encompasses exactly what we are trying to achieve by building components\nusing atomic design.\nIt's important to note that our front-end atomic architecture is still evolving.  Our components are broken down into templates, organisms, molecules, and atoms.\nWe opted not to use the page component, although it exists in atomic design.\nOur components are composed of HTML, CSS, and JS (JavaScript).\nIf a component doesn\u2019t have user interactions or require styling,\nthen it won\u2019t have an associated JS and/or CSS file.  We compose our atomic components as follows:", 
            "title": "Notes on Atomic Design"
        }, 
        {
            "location": "/atomic-structure/#atoms", 
            "text": "Prefixed with \u201ca-\u201d in CSS, JavaScript, and HTML files.", 
            "title": "Atoms"
        }, 
        {
            "location": "/atomic-structure/#html", 
            "text": "div class= a-overlay u-hidden /div", 
            "title": "HTML"
        }, 
        {
            "location": "/atomic-structure/#css", 
            "text": ".a-overlay {\n    // Only show overlay at mobile/tablet size.\n    .respond-to-max( @bp-sm-max, {\n        height: 100%;\n        width: 100%;\n \u2026", 
            "title": "CSS"
        }, 
        {
            "location": "/atomic-structure/#molecules", 
            "text": "Prefixed with \u201cm-\u201d in CSS, JavaScript, and HTML files.", 
            "title": "Molecules"
        }, 
        {
            "location": "/atomic-structure/#html_1", 
            "text": "div class= m-notification\n            m-notification__visible\n            m-notification__error \n     data-js-hook= state_atomic_init \n    {{ svg_icon('error') }}\n     div class= m-notification_content  role= alert \n         div class= h4 m-notification_message Page not found. /div \n     /div  /div", 
            "title": "HTML"
        }, 
        {
            "location": "/atomic-structure/#css_1", 
            "text": ".m-notification {\n    display: none;\n    position: relative;\n    padding: @notification-padding__px;\n    \u2026", 
            "title": "CSS"
        }, 
        {
            "location": "/atomic-structure/#javascript", 
            "text": "function Notification( element ) {\n   const BASE_CLASS = 'm-notification';\n\n   // Constants for the state of this Notification.\n   const SUCCESS = 'success';\n   const WARNING = 'warning';\n   const ERROR = 'error';\n\n   // Constants for the Notification modifiers.\n   const MODIFIER_VISIBLE = BASE_CLASS + '__visible';\n   const _dom = atomicHelpers.checkDom( element, BASE_CLASS );\n   const _contentDom = _dom.querySelector( '.' + BASE_CLASS + '_content' );\n   \u2026  The notification molecule can be instantiated with the following code:  const notification = new Notification( _dom );\nnotification.init();", 
            "title": "JavaScript"
        }, 
        {
            "location": "/atomic-structure/#organisms", 
            "text": "Prefixed with \u201co-\u201d in CSS, JavaScript, and HTML.", 
            "title": "Organisms"
        }, 
        {
            "location": "/atomic-structure/#html_2", 
            "text": "div class= o-expandable\n            o-expandable__borders\n            o-expandable__midtone\n            o-expandable__expanded \n     data-js-hook= state_atomic_init \n     button class= o-expandable_target  aria-pressed= true \n         div class= o-expandable_header \n        \u2026  JavaScript:   function Expandable( element ) {\n  const BASE_CLASS = 'o-expandable';\n\n  // Bitwise flags for the state of this Expandable.\n  const COLLAPSED = 0;\n  const COLLAPSING = 1;\n  const EXPANDING = 2;\n  const EXPANDED = 3;\n\n  // The Expandable element will directly be the Expandable\n  // when used in an ExpandableGroup, otherwise it can be the parent container.\n  const _dom = atomicHelpers.checkDom( element, BASE_CLASS );\n  const _target = _dom.querySelector( '.' + BASE_CLASS + '_target' );\n  const _content = _dom.querySelector( '.' + BASE_CLASS + '_content' );\n  \u2026  The Expandable organism can be instantiated with the following code:  const expandable = new Expandable( _dom.querySelector( '.o-expandable' ) );\nexpandable.init( _expandable.EXPANDED );  or  const atomicHelpers = require( '../../modules/util/atomic-helpers' );\nconst Expandable = require( '../../organisms/Expandable' );\natomicHelpers.instantiateAll( '.o-expandable', Expandable );", 
            "title": "HTML"
        }, 
        {
            "location": "/atomic-structure/#templates", 
            "text": "Prefixed with \u201ct-\u201d in CSS, JavaScript, and HTML.  View all available templates  that can be extended or reused to create pages.", 
            "title": "Templates"
        }, 
        {
            "location": "/atomic-structure/#css_2", 
            "text": ".t-careers {\n     _social .m-social-media {\n        float: right;\n    }\n    \u2026", 
            "title": "CSS"
        }, 
        {
            "location": "/atomic-structure/#folder-structure", 
            "text": "Our atomic components are separated and named based on asset type. HTML, CSS, and JavaScript for each component are in separate directories.", 
            "title": "Folder structure"
        }, 
        {
            "location": "/atomic-structure/#current-structure", 
            "text": "", 
            "title": "Current structure"
        }, 
        {
            "location": "/atomic-structure/#html_3", 
            "text": "cfgov-refresh/cfgov/jinja2/v1/_includes/atoms/\ncfgov-refresh/cfgov/jinja2/v1/_includes/molecules/\ncfgov-refresh/cfgov/jinja2/v1/_includes/organisms/", 
            "title": "HTML"
        }, 
        {
            "location": "/atomic-structure/#css_3", 
            "text": "cfgov-refresh/cfgov/unprocessed/css/atoms/\ncfgov-refresh/cfgov/unprocessed/css/molecules/\ncfgov-refresh/cfgov/unprocessed/css/organisms/", 
            "title": "CSS"
        }, 
        {
            "location": "/atomic-structure/#javascript_1", 
            "text": "cfgov-refresh/cfgov/unprocessed/js/atoms/\ncfgov-refresh/cfgov/unprocessed/js/molecules/\ncfgov-refresh/cfgov/unprocessed/js/organisms/", 
            "title": "JavaScript"
        }, 
        {
            "location": "/atomic-structure/#test", 
            "text": "cfgov-refresh/test/unit_tests/atoms/\ncfgov-refresh/test/unit_tests/molecules/\ncfgov-refresh/test/unit_tests/organisms/", 
            "title": "Test"
        }, 
        {
            "location": "/atomic-structure/#javascript-architecture", 
            "text": "JavaScript components are built to be rendered on the server and then enhanced via JavaScript on the client. The basic interface for the components is as follows:  function AtomicComponent( domElement ) {\n    // Ensure the passed in Element is in the DOM.\n    // Query and store references to sub-elements.\n    // Instantiate child atomic components.\n    // Bind necessary events for referenced DOM elements.\n    // Perform other initialization related tasks.\n    this.init = function init(){}\n\n    // General teardown function\n    // We don't remove the element from the DOM so\n    // we need to unbind the events.\n    this.destroy = function destroy(){}\n}  We generally favor composition over inheritance.\nYou can get more information by reading the following:", 
            "title": "JavaScript architecture"
        }, 
        {
            "location": "/atomic-structure/#articles", 
            "text": "A Simple Challenge to Classical Inheritance Fans  Composition over Inheritance (Youtube)", 
            "title": "Articles"
        }, 
        {
            "location": "/atomic-structure/#component-build-pipeline", 
            "text": "", 
            "title": "Component build pipeline"
        }, 
        {
            "location": "/atomic-structure/#gulp", 
            "text": "Gulp is used as a task automation tool. Tasks include compiling CSS, creating a standard webpack workflow for bundling scripts, minifying code, linting, image optimizing, running unit tests, and  more .", 
            "title": "Gulp"
        }, 
        {
            "location": "/atomic-structure/#webpack", 
            "text": "Wepback is used as a module bundler although it's capable of more.\nWe create page, global, and atomic specific bundles.\nThe configuration for the bundles is contained in config/webpack-config.js.\nAn explanation for the usage of each bundle is contained in scripts.js.", 
            "title": "Webpack"
        }, 
        {
            "location": "/atomic-structure/#routes", 
            "text": "Routes are used to serve JavaScript bundles to the browser based\non the requested URL or Wagtail page Media property.\nThis happens via code contained in  base.html . This file serves as the base HTML template for serving up assets and content.  View base.html on Github .", 
            "title": "Routes"
        }, 
        {
            "location": "/atomic-structure/#wagtail-page-media-property", 
            "text": "Each atomic component has a media property that list the JavaScript files\nthat should be rendered via base.html.\nWhen a page is requested via the browser, code contained in base.html will\nloop all atomic components for the requested page and render\nthe appropriate atomic JavaScript bundles.  Here is an example of the media property on a component from the  Email signup organism :  class Media:\n    js = ['email-signup.js']  This will load the  email-signup.js  script on any page that includes the Email Signup organism in its template.", 
            "title": "Wagtail page media property"
        }, 
        {
            "location": "/testing-fe/", 
            "text": "Browser tests\n\u00b6\n\n\nQuick start:\n\u00b6\n\n\nTo run browser tests, open a new Terminal window or tab and change to the project directory,\nthen tell gulp to start the tests:\n\n\ngulp build\ngulp test:acceptance ( tox -e acceptance can be run as well )\n\n\n\nThere are several options you can pass to run a particular suite of tests,\nto run a particular list of features,\nand/or to run it in \"fast\" mode:\n\n\ngulp test:acceptance --suite=wagtail-admin ( runs just the wagtail-admin suite )\ngulp test:acceptance --specs=multi-select.feature ( runs just the multi-select feature )\ngulp test:acceptance --tags=@mobile ( runs all scenarios tagged with @mobile )\ngulp test:acceptance --recreate ( runs the tests and recreates the virtual environment )\n\n\n\nThe same options can be used with tox (--omitted):\n\n\ntox -e acceptance suite=wagtail-admin\ntox -e acceptance specs=multi-select.feature\ntox -e acceptance tags=@mobile\n\n\n\nThese tests will run on their own server; you do not need to be running your development server.\n\n\nCucumber - tool for running automated tests written in plain language\n\u00b6\n\n\nBelow are some suggested standards for Cucumber Feature files:\n\n\nTable copied from \nhttps://saucelabs.com/blog/write-great-cucumber-tests\n by Greg Sypolt, with moderate modifications\n\n\n\n   \n\n      \n\n         \nFeature Files\n\n         \nEvery *.feature file consists in a single feature, focused on the business value.\n\n      \n\n      \n\n      \nGherkin\n\n         \n\n            \nFeature:Title (one line describing the story)\nNarrative Description: As a [role], I want [feature], so that I [benefit]\n\nScenario: Title (acceptance criteria of user story)\n  Given [context]\n  And [some more context]...\n  When [event]\n  Then [outcome]\n  And [another outcome]...\n\nScenario:...\n\n\n\n\n      \n\n      \n\n         \nGiven, When, and Then Statements\n\n         \n\n           There might be some confusion surrounding where to put the verification step in the Given, When, Then sequence. Each statement has a purpose. \n\n\n\n\nGiven\n is the pre-condition to put the system into a known state before the user starts interacting with the application\n\n\nWhen\n describes the key action the user performs\n\n\nThen\n is observing the expected outcome\n\n\n\n\nJust remember the \n\u2018then\u2019\n step is an acceptance criteria of the story.\n   \n\n      \n\n      \n\n         \nBackground\n\n         \nThe background needs to be used wisely. If you use the same steps at the beginning of all scenarios of a feature, put them into the feature\u2019s background scenario. The background steps are run before each scenario.\n\n\nBackground:\n  Given I am logged into Wagtail as an admin\n  And I create a Wagtail Sublanding Page\n  And I open the content menu\n\n        \n\n      \n\n      \n\n         \nScenarios\n\n         \nKeep each scenario independent. The scenarios should run independently, without any dependencies on other scenarios.  Scenarios should be between 3 to 6 statements, if possible.\n\n      \n\n      \n\n         \nScenario Outline\n\n         \nIf you identify the need to use a scenario outline, take a step back and ask the following question: Is it necessary to repeat this scenario \u2018x\u2019 amount of times just to exercise the different combination of data? In most cases, one time is enough for UI level testing.\n\n      \n\n      \n\n         \nDeclarative Vs Imperative Scenarios\n\n         \n\n            The declarative style describes behavior at a higher level, which improves the readability of the feature by abstracting out the implementation details of the application.  The imperative style is more verbose but better describes the expected behavior.  Either style is acceptable.\n\n\nExample: Declarative\n\n\n\nScenario:User logs in\n  Given I am on the homepage\n  When I log in\n  Then I should see a login notification\n\n\n\nExample: Imperative\n\n\n\nScenario: User logs in\n  Given I am on the homepage\n  When I click on the \"Login\" button\n  And I fill in the \"Email\" field with \"\n\"\n  And I fill in the \"Password\" field with \"secret\"\n  And I click on \"Submit\"\n  Then I should see \"Welcome to the app, John Doe\"\n\n\n         \n\n      \n\n   \n\n\n\n\nSauce Connect - send tests to the cloud\n\u00b6\n\n\nSauce Labs can be used to run tests remotely in the cloud.\n\n\n\n\n\n\nLog into \nhttps://saucelabs.com/account\n.\n\n\n\n\n\n\nUpdate and uncomment the \nSAUCE_USERNAME\n, \nSAUCE_ACCESS_KEY\n,\n   and \nSAUCE_SELENIUM_URL\n values in your \n.env\n file.\n   The access key can be found on the Sauce Labs\n   \nuser settings page\n.\n\n\n\n\n\n\nReload the settings with \nsource .env\n.\n\n\n\n\n\n\nRun the tests with \ngulp test:acceptance --sauce\n.\n\n\n\n\n\n\nMonitor progress of the tests\n   on the \nSauce Labs dashboard\n Automated Tests tab.\n\n\n\n\n\n\n\n\nNote\n\n\nIf you get the error \nError: ENOTFOUND getaddrinfo ENOTFOUND\n\nwhile running a test, it likely means that Sauce Connect is not running.\n\n\n\n\nManual test configuration\n\u00b6\n\n\nA number of command-line arguments can be set to test particular configurations:\n\n\n\n\n--suite\n: Choose a particular suite or suites to run.\n   For example, \ngulp test:acceptance --suite=content\n or \ngulp test:acceptance --suite=content,functional\n.\n\n\n--specs\n: Choose a particular spec or specs to run.\n   For example, \ngulp test:acceptance --specs=header.feature\n, \ngulp test:acceptance --specs=header.feature,pagination.feature\n, or \ngulp test:acceptance --specs=filterable*.feature\n. If \n--suite\n is specified, this argument will be ignored. If neither \n--suite\n nor \n--specs\n are specified, all specs will be run.\n\n\n--windowSize\n: Set the window size in pixels in \nw,h\n format.\n   For example, \ngulp test:acceptance --windowSize=900,400\n.\n\n\n--browserName\n: Set the browser to run.\n   For example, \ngulp test:acceptance --browserName=firefox\n.\n\n\n--version\n: Set the browser version to run.\n   For example, \ngulp test:acceptance --version='44.0'\n.\n\n\n--platform\n: Set the OS platform to run.\n   For example, \ngulp test:acceptance --platform='osx 10.10'\n.\n\n\n--sauce\n: Whether to run on Sauce Labs or not.\n   For example, \ngulp test:acceptance --sauce=false\n.\n\n\n\n\nTests\n\u00b6\n\n\nTests are organized into suites under the \ntest/browser_tests/cucumber/features\n directory. Any new tests should be added to an existing suite (e.g. \"default\"), or placed into a new suite directory. All tests start with writing a \n.feature\n spec in one of these suites, and then adding corresponding step definitions, found in \ntest/browser_tests/cucumber/step_definitions\n.\n\n\nFurther reading\n\u00b6\n\n\n\n\nCucumber features\n\n\nProtractor\n\n\nSelect elements on a page\n\n\nWriting Jasmin expectations\n.\n\n\nUnderstanding Page Objects\n\n\n\n\nPerformance testing\n\u00b6\n\n\nTo audit if the site complies with performance best practices and guidelines,\nrun \ngulp audit:perf\n.\n\n\nThe audit will run against\n\nGoogle's PageSpeed Insights\n.\n\n\nUnit testing\n\u00b6\n\n\nJavaScript unit tests\n\u00b6\n\n\nJavaScript module unit tests are run with \ngulp test:unit\n.\n\n\nIf you want to run individual spec files, pass in the \n--specs\n command-line\nargument with the path to the spec,\nsuch as \ngulp test:unit --specs=js/modules/Tree-spec.js\n.\nAlso, a directory of unit tests can be run,\nsuch as \ngulp test:unit --specs=js/modules/transition/\n.\n\n\nAccessibility Testing\n\u00b6\n\n\nRun the acceptance tests with an \n--a11y\n flag (i.e. \ngulp test:acceptance --a11y\n)\nto check every webpage for WCAG and Section 508 compliancy using Protractor's\n\naccessibility plugin\n.\n\n\nIf you'd like to audit a specific page, use \ngulp audit:a11y\n:\n\n\n\n\nEnable the environment variable \nACHECKER_ID\n in your \n.env\n file.\n     Get a free \nAChecker API ID\n for the value.\n\n\nReload your \n.env\n with \nsource ./.env\n while in the project root directory.\n\n\nRun \ngulp audit:a11y\n to run an audit on the homepage.\n\n\nTo test a page aside from the homepage, add the \n--u=\npath_to_test\n flag.\n     For example, \ngulp audit:a11y --u=contact-us\n\n     or \ngulp audit:a11y --u=the-bureau/bureau-structure/\n.\n\n\n\n\nSource code linting\n\u00b6\n\n\nThe default test task includes linting of the JavaScript source, build,\nand test files.\nUse the \ngulp lint\n command from the command-line to run the ESLint linter,\nwhich checks the JavaScript against the rules configured in \n.eslintrc\n.\n\nSee the ESLint docs\n\nfor detailed rule descriptions.\n\n\nThere are a number of options to the command:\n\n\n\n\ngulp lint:build\n: Lint only the gulp build scripts.\n\n\ngulp lint:test\n: Lint only the test scripts.\n\n\ngulp lint:scripts\n: Lint only the project source scripts.\n\n\n--fix\n: Add this flag (like \ngulp lint --fix\n or \ngulp lint:build --fix\n)\n   to auto-fix some errors, where ESLint has support to do so.", 
            "title": "Testing"
        }, 
        {
            "location": "/testing-fe/#browser-tests", 
            "text": "", 
            "title": "Browser tests"
        }, 
        {
            "location": "/testing-fe/#quick-start", 
            "text": "To run browser tests, open a new Terminal window or tab and change to the project directory,\nthen tell gulp to start the tests:  gulp build\ngulp test:acceptance ( tox -e acceptance can be run as well )  There are several options you can pass to run a particular suite of tests,\nto run a particular list of features,\nand/or to run it in \"fast\" mode:  gulp test:acceptance --suite=wagtail-admin ( runs just the wagtail-admin suite )\ngulp test:acceptance --specs=multi-select.feature ( runs just the multi-select feature )\ngulp test:acceptance --tags=@mobile ( runs all scenarios tagged with @mobile )\ngulp test:acceptance --recreate ( runs the tests and recreates the virtual environment )  The same options can be used with tox (--omitted):  tox -e acceptance suite=wagtail-admin\ntox -e acceptance specs=multi-select.feature\ntox -e acceptance tags=@mobile  These tests will run on their own server; you do not need to be running your development server.", 
            "title": "Quick start:"
        }, 
        {
            "location": "/testing-fe/#cucumber-tool-for-running-automated-tests-written-in-plain-language", 
            "text": "Below are some suggested standards for Cucumber Feature files:  Table copied from  https://saucelabs.com/blog/write-great-cucumber-tests  by Greg Sypolt, with moderate modifications  \n    \n       \n          Feature Files \n          Every *.feature file consists in a single feature, focused on the business value. \n       \n       \n       Gherkin \n          \n             Feature:Title (one line describing the story)\nNarrative Description: As a [role], I want [feature], so that I [benefit] \nScenario: Title (acceptance criteria of user story)\n  Given [context]\n  And [some more context]...\n  When [event]\n  Then [outcome]\n  And [another outcome]... \nScenario:...  \n       \n       \n          Given, When, and Then Statements \n          \n           There might be some confusion surrounding where to put the verification step in the Given, When, Then sequence. Each statement has a purpose.    Given  is the pre-condition to put the system into a known state before the user starts interacting with the application  When  describes the key action the user performs  Then  is observing the expected outcome   Just remember the  \u2018then\u2019  step is an acceptance criteria of the story.\n    \n       \n       \n          Background \n          The background needs to be used wisely. If you use the same steps at the beginning of all scenarios of a feature, put them into the feature\u2019s background scenario. The background steps are run before each scenario. \nBackground:\n  Given I am logged into Wagtail as an admin\n  And I create a Wagtail Sublanding Page\n  And I open the content menu \n         \n       \n       \n          Scenarios \n          Keep each scenario independent. The scenarios should run independently, without any dependencies on other scenarios.  Scenarios should be between 3 to 6 statements, if possible. \n       \n       \n          Scenario Outline \n          If you identify the need to use a scenario outline, take a step back and ask the following question: Is it necessary to repeat this scenario \u2018x\u2019 amount of times just to exercise the different combination of data? In most cases, one time is enough for UI level testing. \n       \n       \n          Declarative Vs Imperative Scenarios \n          \n            The declarative style describes behavior at a higher level, which improves the readability of the feature by abstracting out the implementation details of the application.  The imperative style is more verbose but better describes the expected behavior.  Either style is acceptable.  Example: Declarative  \nScenario:User logs in\n  Given I am on the homepage\n  When I log in\n  Then I should see a login notification  Example: Imperative  \nScenario: User logs in\n  Given I am on the homepage\n  When I click on the \"Login\" button\n  And I fill in the \"Email\" field with \" \"\n  And I fill in the \"Password\" field with \"secret\"\n  And I click on \"Submit\"\n  Then I should see \"Welcome to the app, John Doe\"", 
            "title": "Cucumber - tool for running automated tests written in plain language"
        }, 
        {
            "location": "/testing-fe/#sauce-connect-send-tests-to-the-cloud", 
            "text": "Sauce Labs can be used to run tests remotely in the cloud.    Log into  https://saucelabs.com/account .    Update and uncomment the  SAUCE_USERNAME ,  SAUCE_ACCESS_KEY ,\n   and  SAUCE_SELENIUM_URL  values in your  .env  file.\n   The access key can be found on the Sauce Labs\n    user settings page .    Reload the settings with  source .env .    Run the tests with  gulp test:acceptance --sauce .    Monitor progress of the tests\n   on the  Sauce Labs dashboard  Automated Tests tab.     Note  If you get the error  Error: ENOTFOUND getaddrinfo ENOTFOUND \nwhile running a test, it likely means that Sauce Connect is not running.", 
            "title": "Sauce Connect - send tests to the cloud"
        }, 
        {
            "location": "/testing-fe/#manual-test-configuration", 
            "text": "A number of command-line arguments can be set to test particular configurations:   --suite : Choose a particular suite or suites to run.\n   For example,  gulp test:acceptance --suite=content  or  gulp test:acceptance --suite=content,functional .  --specs : Choose a particular spec or specs to run.\n   For example,  gulp test:acceptance --specs=header.feature ,  gulp test:acceptance --specs=header.feature,pagination.feature , or  gulp test:acceptance --specs=filterable*.feature . If  --suite  is specified, this argument will be ignored. If neither  --suite  nor  --specs  are specified, all specs will be run.  --windowSize : Set the window size in pixels in  w,h  format.\n   For example,  gulp test:acceptance --windowSize=900,400 .  --browserName : Set the browser to run.\n   For example,  gulp test:acceptance --browserName=firefox .  --version : Set the browser version to run.\n   For example,  gulp test:acceptance --version='44.0' .  --platform : Set the OS platform to run.\n   For example,  gulp test:acceptance --platform='osx 10.10' .  --sauce : Whether to run on Sauce Labs or not.\n   For example,  gulp test:acceptance --sauce=false .", 
            "title": "Manual test configuration"
        }, 
        {
            "location": "/testing-fe/#tests", 
            "text": "Tests are organized into suites under the  test/browser_tests/cucumber/features  directory. Any new tests should be added to an existing suite (e.g. \"default\"), or placed into a new suite directory. All tests start with writing a  .feature  spec in one of these suites, and then adding corresponding step definitions, found in  test/browser_tests/cucumber/step_definitions .", 
            "title": "Tests"
        }, 
        {
            "location": "/testing-fe/#further-reading", 
            "text": "Cucumber features  Protractor  Select elements on a page  Writing Jasmin expectations .  Understanding Page Objects", 
            "title": "Further reading"
        }, 
        {
            "location": "/testing-fe/#performance-testing", 
            "text": "To audit if the site complies with performance best practices and guidelines,\nrun  gulp audit:perf .  The audit will run against Google's PageSpeed Insights .", 
            "title": "Performance testing"
        }, 
        {
            "location": "/testing-fe/#unit-testing", 
            "text": "", 
            "title": "Unit testing"
        }, 
        {
            "location": "/testing-fe/#javascript-unit-tests", 
            "text": "JavaScript module unit tests are run with  gulp test:unit .  If you want to run individual spec files, pass in the  --specs  command-line\nargument with the path to the spec,\nsuch as  gulp test:unit --specs=js/modules/Tree-spec.js .\nAlso, a directory of unit tests can be run,\nsuch as  gulp test:unit --specs=js/modules/transition/ .", 
            "title": "JavaScript unit tests"
        }, 
        {
            "location": "/testing-fe/#accessibility-testing", 
            "text": "Run the acceptance tests with an  --a11y  flag (i.e.  gulp test:acceptance --a11y )\nto check every webpage for WCAG and Section 508 compliancy using Protractor's accessibility plugin .  If you'd like to audit a specific page, use  gulp audit:a11y :   Enable the environment variable  ACHECKER_ID  in your  .env  file.\n     Get a free  AChecker API ID  for the value.  Reload your  .env  with  source ./.env  while in the project root directory.  Run  gulp audit:a11y  to run an audit on the homepage.  To test a page aside from the homepage, add the  --u= path_to_test  flag.\n     For example,  gulp audit:a11y --u=contact-us \n     or  gulp audit:a11y --u=the-bureau/bureau-structure/ .", 
            "title": "Accessibility Testing"
        }, 
        {
            "location": "/testing-fe/#source-code-linting", 
            "text": "The default test task includes linting of the JavaScript source, build,\nand test files.\nUse the  gulp lint  command from the command-line to run the ESLint linter,\nwhich checks the JavaScript against the rules configured in  .eslintrc . See the ESLint docs \nfor detailed rule descriptions.  There are a number of options to the command:   gulp lint:build : Lint only the gulp build scripts.  gulp lint:test : Lint only the test scripts.  gulp lint:scripts : Lint only the project source scripts.  --fix : Add this flag (like  gulp lint --fix  or  gulp lint:build --fix )\n   to auto-fix some errors, where ESLint has support to do so.", 
            "title": "Source code linting"
        }, 
        {
            "location": "/development-tips/", 
            "text": "Development tips\n\u00b6\n\n\nTIP: Developing on nested satellite apps\n\u00b6\n\n\nSome projects can sit inside cfgov-refresh, but manage their own asset\ndependencies. These projects have their own package.json and base templates.\n\n\nThe structure looks like this:\n\n\nnpm modules\n\u00b6\n\n\n\n\nApp's own dependency list is in\n  \ncfgov/unprocessed/apps/[project namespace]/package.json\n\n\nApp's \nnode_modules\n path is listed in the Travis config\n  \nhttps://github.com/cfpb/cfgov-refresh/blob/master/.travis.yml#L10\n\n  so that their dependencies will be available when Travis runs.\n\n\n\n\nWebpack\n\u00b6\n\n\n\n\nApps may include their own webpack-config.js configuration that adjusts how\n  their app-specific assets should be built. This configuration appears in\n  \ncfgov/unprocessed/apps/[project namespace]/webpack-config.js\n\n\n\n\nBrowserlist\n\u00b6\n\n\n\n\nApps may include a\n  \nbrowserlist config\n\n  file, which is automatically picked up by \nbabel-preset-env\n inside the\n  webpack config, if no \nbrowsers\n option is supplied.\n\n\n\n\nTemplates\n\u00b6\n\n\n\n\nApps use a jinja template that extends the \nbase.html\n\n  template used by the rest of the site.\n  This template would reside in \ncfgov/jinja2/v1/[project namespace]/index.html\n\n  or similar (for example, \nowning-a-home\n).\n\n\n\n\n\n\nNote\n\n\nA template may support a non-standard browser, like an older IE version,\nby including the required dependencies, polyfills, etc. in its\ntemplate's \n{% block css %}\n or \n{% block javascript scoped %}\n blocks.\n\n\n\n\nTIP: Loading satellite apps\n\u00b6\n\n\nSome projects fit within the cfgov-refresh architecture,\nbut are not fully incorporated into the project.\nThese are known as \"satellite apps.\"\n\n\nSatellite apps are listed in the\n\noptional-public.txt\n\nrequirements file.\n\n\nIn addition to the aforementioned list,\n\nHMDA Explorer\n and\n\nRural or Underserved\n,\nhave their own installation requirements.\n\n\nIf using Docker, follow\n\nthese guidelines\n.\n\n\nOtherwise, if not using Docker, follow these guidelines:\n\n\n\n\nBuild the third-party projects per their directions\n\n\nStop the web server and return to \ncfgov-refresh\n\n\nRun \npip install -e ../\nsibling\n to load the projects' dependencies\n\n\n\n\n\n\nNote\n\n\nDo not install the projects directly into the \ncfgov-refresh\n directory.\nClone and install the projects as siblings to \ncfgov-refresh\n,\nso that they share the same parent directory (\n~/Projects\n or similar).\n\n\n\n\nTIP: Working with the templates\n\u00b6\n\n\nFront-End Template/Asset Locations\n\u00b6\n\n\nTemplates\n that are served by the Django server: \ncfgov\\jinja2\\v1\n\n\nStatic assets\n prior to processing (minifying etc.): \ncfgov\\unprocessed\n.\n\n\n\n\nNote\n\n\nAfter running \ngulp build\n the site's assets are copied over to \ncfgov\\static_built\n,\nready to be served by Django.\n\n\n\n\nSimple static template setup\n\u00b6\n\n\nBy default, Django will render pages with accordance to the URL pattern defined\nfor it. For example, going to \nhttp://localhost:8000/the-bureau/index.html\n\n(or \nhttp://localhost:8000/the-bureau/\n) renders \n/the-bureau/index.html\n from\nthe \ncfgov\n app folder's \njinja2/v1\n templates folder as processed\nby the \nJinja2\n templating engine.\n\n\nTIP: Debugging site performance\n\u00b6\n\n\nWhen running locally it is possible to enable the\n\nDjango Debug Toolbar\n\nby defining the \nENABLE_DEBUG_TOOLBAR\n environment variable:\n\n\n$ ENABLE_DEBUG_TOOLBAR=1 ./runserver.sh\n\n\n\nThis tool exposes various useful pieces of information about things like HTTP headers,\nDjango settings, SQL queries, and template variables. Note that running with the toolbar on\nmay have an impact on local server performance.\n\n\nTIP: Updating the documentation\n\u00b6\n\n\nOur documentation is written as Markdown files and served in GitHub pages\nby \nmkdocs\n.\n\n\nTo update the docs in GitHub Pages once a pull request has been merged,\nmkdocs provides \na helpful command\n:\n\n\nmkdocs gh-deploy --clean", 
            "title": "Development tips"
        }, 
        {
            "location": "/development-tips/#development-tips", 
            "text": "", 
            "title": "Development tips"
        }, 
        {
            "location": "/development-tips/#tip-developing-on-nested-satellite-apps", 
            "text": "Some projects can sit inside cfgov-refresh, but manage their own asset\ndependencies. These projects have their own package.json and base templates.  The structure looks like this:", 
            "title": "TIP: Developing on nested satellite apps"
        }, 
        {
            "location": "/development-tips/#npm-modules", 
            "text": "App's own dependency list is in\n   cfgov/unprocessed/apps/[project namespace]/package.json  App's  node_modules  path is listed in the Travis config\n   https://github.com/cfpb/cfgov-refresh/blob/master/.travis.yml#L10 \n  so that their dependencies will be available when Travis runs.", 
            "title": "npm modules"
        }, 
        {
            "location": "/development-tips/#webpack", 
            "text": "Apps may include their own webpack-config.js configuration that adjusts how\n  their app-specific assets should be built. This configuration appears in\n   cfgov/unprocessed/apps/[project namespace]/webpack-config.js", 
            "title": "Webpack"
        }, 
        {
            "location": "/development-tips/#browserlist", 
            "text": "Apps may include a\n   browserlist config \n  file, which is automatically picked up by  babel-preset-env  inside the\n  webpack config, if no  browsers  option is supplied.", 
            "title": "Browserlist"
        }, 
        {
            "location": "/development-tips/#templates", 
            "text": "Apps use a jinja template that extends the  base.html \n  template used by the rest of the site.\n  This template would reside in  cfgov/jinja2/v1/[project namespace]/index.html \n  or similar (for example,  owning-a-home ).    Note  A template may support a non-standard browser, like an older IE version,\nby including the required dependencies, polyfills, etc. in its\ntemplate's  {% block css %}  or  {% block javascript scoped %}  blocks.", 
            "title": "Templates"
        }, 
        {
            "location": "/development-tips/#tip-loading-satellite-apps", 
            "text": "Some projects fit within the cfgov-refresh architecture,\nbut are not fully incorporated into the project.\nThese are known as \"satellite apps.\"  Satellite apps are listed in the optional-public.txt \nrequirements file.  In addition to the aforementioned list, HMDA Explorer  and Rural or Underserved ,\nhave their own installation requirements.  If using Docker, follow these guidelines .  Otherwise, if not using Docker, follow these guidelines:   Build the third-party projects per their directions  Stop the web server and return to  cfgov-refresh  Run  pip install -e ../ sibling  to load the projects' dependencies    Note  Do not install the projects directly into the  cfgov-refresh  directory.\nClone and install the projects as siblings to  cfgov-refresh ,\nso that they share the same parent directory ( ~/Projects  or similar).", 
            "title": "TIP: Loading satellite apps"
        }, 
        {
            "location": "/development-tips/#tip-working-with-the-templates", 
            "text": "", 
            "title": "TIP: Working with the templates"
        }, 
        {
            "location": "/development-tips/#front-end-templateasset-locations", 
            "text": "Templates  that are served by the Django server:  cfgov\\jinja2\\v1  Static assets  prior to processing (minifying etc.):  cfgov\\unprocessed .   Note  After running  gulp build  the site's assets are copied over to  cfgov\\static_built ,\nready to be served by Django.", 
            "title": "Front-End Template/Asset Locations"
        }, 
        {
            "location": "/development-tips/#simple-static-template-setup", 
            "text": "By default, Django will render pages with accordance to the URL pattern defined\nfor it. For example, going to  http://localhost:8000/the-bureau/index.html \n(or  http://localhost:8000/the-bureau/ ) renders  /the-bureau/index.html  from\nthe  cfgov  app folder's  jinja2/v1  templates folder as processed\nby the  Jinja2  templating engine.", 
            "title": "Simple static template setup"
        }, 
        {
            "location": "/development-tips/#tip-debugging-site-performance", 
            "text": "When running locally it is possible to enable the Django Debug Toolbar \nby defining the  ENABLE_DEBUG_TOOLBAR  environment variable:  $ ENABLE_DEBUG_TOOLBAR=1 ./runserver.sh  This tool exposes various useful pieces of information about things like HTTP headers,\nDjango settings, SQL queries, and template variables. Note that running with the toolbar on\nmay have an impact on local server performance.", 
            "title": "TIP: Debugging site performance"
        }, 
        {
            "location": "/development-tips/#tip-updating-the-documentation", 
            "text": "Our documentation is written as Markdown files and served in GitHub pages\nby  mkdocs .  To update the docs in GitHub Pages once a pull request has been merged,\nmkdocs provides  a helpful command :  mkdocs gh-deploy --clean", 
            "title": "TIP: Updating the documentation"
        }, 
        {
            "location": "/ask-cfpb/", 
            "text": "Ask CFPB API\n\u00b6\n\n\nThis API provides search access to the English and Spanish content behind \nAsk CFPB\n and \nObtener respuestas\n.\n\n\nThe financial topics covered include:\n\n\n\n\nAuto loans\n\n\nBank accounts and services\n\n\nCredit cards\n\n\nCredit reports and scores\n\n\nDebt collection\n\n\nFamilies and money\n\n\nMoney transfers\n\n\nMortgages\n\n\nPayday loans\n\n\nPrepaid cards\n\n\nStudent loans\n\n\n\n\nUsage\n\u00b6\n\n\nThe API is a read-only resource that delivers search results in \njson\n format.\n\n\nRequests follow this pattern:\n\n\n\n\nhttps://www.consumerfinance.gov/ask-cfpb/search/json/?q=[SEARCH TERMS]\n\n\n\n\nThe json response will includes a list of results, each with a question, an answer, and a URL for the related CFPB page.\nIf no results are found, the \"suggestion\" field will offer a more promising search term if one can be found.\n\n\nThe payload for the search term \"tuition\" would look like this, but with more result entries:\n\n\n{\n  query: \ntuition\n,\n  suggestion: null,\n  result_query: \ntuition\n,\n  results: [\n    {\n      url: \nhttps://www.consumerfinance.gov/ask-cfpb/what-is-a-tuition-payment-plan-en-563/\n,\n      text: \nTuition payment plans, also called tuition installment plans, are short-term (12 months or less) payment plans that split your college bills into equal monthly payments. Tuition installment plans can be an alternative to student loans if you can afford to pay tuition, just not in a lump sum at the start of the semester or quarter. These payment plans do not generally charge interest, but they may have up-front fees. What is a tuition payment plan?\n,\n      question: \nWhat is a tuition payment plan?\n\n    }\n  ]\n}\n\n\n\nSpanish content\n\u00b6\n\n\nFor questions and answers in Spanish, requests should follow this pattern:\n\n\n\n\nhttps://www.consumerfinance.gov/es/obtener-respuestas/buscar/json/?q=[SPANISH SEARCH TERMS]\n\n\n\n\nThe payload for the Spanish search term \"vehiculo\" would look like this, but with more result entries:\n\n\n{\n  query: \nvehiculo\n,\n  suggestion: null,\n  result_query: \nvehiculo\n,\n  results: [\n    {\n      url: \nhttps://www.consumerfinance.gov/es/obtener-respuestas/como-puedo-averiguar-el-significado-de-los-terminos-de-mi-contrato-de-leasing-es-2047/\n,\n      text: \n Bajo la Ley de Arrendamientos del Consumidor (CLA, por sus siglas en ingl\u00e9s), la persona o compa\u00f1\u00eda de quien usted hace el leasing de un veh\u00edculo, conocida como el \narrendador\n, deber\u00e1 informar por escrito ciertos costos y plazos si el leasing es de m\u00e1s de cuatro meses y si cumple con otros requisitos. La mayor\u00eda de los arrendamientos de veh\u00edculos est\u00e1 sujeta a la CLA. Los siguientes materiales le pueden ayudar a entender los t\u00e9rminos de su contrato de leasing. En el sitio web Comprenda c\u00f3mo funciona la financiaci\u00f3n de veh\u00edculos de la Comisi\u00f3n Federal de Comercio se ofrece la siguiente informaci\u00f3n en espa\u00f1ol: Antes de comprar un veh\u00edculo o hacer un leasing \u00bfDeber\u00eda hacer un leasing para un veh\u00edculo? Glosario de t\u00e9rminos espec\u00edficos M\u00e1s informaci\u00f3n en espa\u00f1ol de GobiernoUSA.gov: Consejos para comprar un auto usado: Arrendamiento con derecho a compra o \u201cleasing\u201d     Bajo la Ley de Arrendamientos del Consumidor (CLA, por sus siglas en ingles), la persona o compania de quien usted hace el leasing de un vehiculo, conocida como el \narrendador\n, debera informar por escrito ciertos costos y plazos si el leasing es de mas de cuatro meses y si cumple con otros requisitos. La mayoria de los arrendamientos de vehiculos esta sujeta a la CLA. Los siguientes materiales le pueden ayudar a entender los terminos de su contrato de leasing. En el sitio web Comprenda como funciona la financiacion de vehiculos de la Comision Federal de Comercio se ofrece la siguiente informacion en espanol: Antes de comprar un vehiculo o hacer un leasing Deberia hacer un leasing para un vehiculo? Glosario de terminos especificos Mas informacion en espanol de GobiernoUSA.gov: Consejos para comprar un auto usado: Arrendamiento con derecho a compra o leasing \u00bfC\u00f3mo puedo averiguar el significado de los t\u00e9rminos de mi contrato de leasing? Como puedo averiguar el significado de los terminos de mi contrato de leasing?\n,\n      question: \n\u00bfC\u00f3mo puedo averiguar el significado de los t\u00e9rminos de mi contrato de leasing?\n\n    }\n  ]\n}", 
            "title": "Ask CFPB"
        }, 
        {
            "location": "/ask-cfpb/#ask-cfpb-api", 
            "text": "This API provides search access to the English and Spanish content behind  Ask CFPB  and  Obtener respuestas .  The financial topics covered include:   Auto loans  Bank accounts and services  Credit cards  Credit reports and scores  Debt collection  Families and money  Money transfers  Mortgages  Payday loans  Prepaid cards  Student loans", 
            "title": "Ask CFPB API"
        }, 
        {
            "location": "/ask-cfpb/#usage", 
            "text": "The API is a read-only resource that delivers search results in  json  format.  Requests follow this pattern:   https://www.consumerfinance.gov/ask-cfpb/search/json/?q=[SEARCH TERMS]   The json response will includes a list of results, each with a question, an answer, and a URL for the related CFPB page.\nIf no results are found, the \"suggestion\" field will offer a more promising search term if one can be found.  The payload for the search term \"tuition\" would look like this, but with more result entries:  {\n  query:  tuition ,\n  suggestion: null,\n  result_query:  tuition ,\n  results: [\n    {\n      url:  https://www.consumerfinance.gov/ask-cfpb/what-is-a-tuition-payment-plan-en-563/ ,\n      text:  Tuition payment plans, also called tuition installment plans, are short-term (12 months or less) payment plans that split your college bills into equal monthly payments. Tuition installment plans can be an alternative to student loans if you can afford to pay tuition, just not in a lump sum at the start of the semester or quarter. These payment plans do not generally charge interest, but they may have up-front fees. What is a tuition payment plan? ,\n      question:  What is a tuition payment plan? \n    }\n  ]\n}", 
            "title": "Usage"
        }, 
        {
            "location": "/ask-cfpb/#spanish-content", 
            "text": "For questions and answers in Spanish, requests should follow this pattern:   https://www.consumerfinance.gov/es/obtener-respuestas/buscar/json/?q=[SPANISH SEARCH TERMS]   The payload for the Spanish search term \"vehiculo\" would look like this, but with more result entries:  {\n  query:  vehiculo ,\n  suggestion: null,\n  result_query:  vehiculo ,\n  results: [\n    {\n      url:  https://www.consumerfinance.gov/es/obtener-respuestas/como-puedo-averiguar-el-significado-de-los-terminos-de-mi-contrato-de-leasing-es-2047/ ,\n      text:   Bajo la Ley de Arrendamientos del Consumidor (CLA, por sus siglas en ingl\u00e9s), la persona o compa\u00f1\u00eda de quien usted hace el leasing de un veh\u00edculo, conocida como el  arrendador , deber\u00e1 informar por escrito ciertos costos y plazos si el leasing es de m\u00e1s de cuatro meses y si cumple con otros requisitos. La mayor\u00eda de los arrendamientos de veh\u00edculos est\u00e1 sujeta a la CLA. Los siguientes materiales le pueden ayudar a entender los t\u00e9rminos de su contrato de leasing. En el sitio web Comprenda c\u00f3mo funciona la financiaci\u00f3n de veh\u00edculos de la Comisi\u00f3n Federal de Comercio se ofrece la siguiente informaci\u00f3n en espa\u00f1ol: Antes de comprar un veh\u00edculo o hacer un leasing \u00bfDeber\u00eda hacer un leasing para un veh\u00edculo? Glosario de t\u00e9rminos espec\u00edficos M\u00e1s informaci\u00f3n en espa\u00f1ol de GobiernoUSA.gov: Consejos para comprar un auto usado: Arrendamiento con derecho a compra o \u201cleasing\u201d     Bajo la Ley de Arrendamientos del Consumidor (CLA, por sus siglas en ingles), la persona o compania de quien usted hace el leasing de un vehiculo, conocida como el  arrendador , debera informar por escrito ciertos costos y plazos si el leasing es de mas de cuatro meses y si cumple con otros requisitos. La mayoria de los arrendamientos de vehiculos esta sujeta a la CLA. Los siguientes materiales le pueden ayudar a entender los terminos de su contrato de leasing. En el sitio web Comprenda como funciona la financiacion de vehiculos de la Comision Federal de Comercio se ofrece la siguiente informacion en espanol: Antes de comprar un vehiculo o hacer un leasing Deberia hacer un leasing para un vehiculo? Glosario de terminos especificos Mas informacion en espanol de GobiernoUSA.gov: Consejos para comprar un auto usado: Arrendamiento con derecho a compra o leasing \u00bfC\u00f3mo puedo averiguar el significado de los t\u00e9rminos de mi contrato de leasing? Como puedo averiguar el significado de los terminos de mi contrato de leasing? ,\n      question:  \u00bfC\u00f3mo puedo averiguar el significado de los t\u00e9rminos de mi contrato de leasing? \n    }\n  ]\n}", 
            "title": "Spanish content"
        }, 
        {
            "location": "/consumer-complaint-database/", 
            "text": "Consumer Complaint Database API\n\u00b6\n\n\nA resource for searching complaints submitted to the CFPB\n\u00b6\n\n\nEach week the CFPB sends thousands of consumers\u2019 complaints about financial products and services to companies for response. Those complaints are \npublished\n on our website after the company responds or after 15 days, whichever comes first.\n\n\nThe API allows automation of the same filtering and searching functions offered to website visitors.\n\n\nDetailed documentation for the search API can be found \nhere\n.\n\n\nNotes\n\u00b6\n\n\nThe database generally updates daily, and contains certain information for each complaint, including the source of the complaint, the date of submission, and the company the complaint was sent to for response. The database also includes information about the actions taken by the company in response to the complaint, such as, whether the company\u2019s response was timely and how the company responded. If the consumer opts to share it and after we take steps to remove personal information, we publish the consumer\u2019s description of what happened. Companies also have the option to select a public response. Company level information should be considered in context of company size and/or market share. Complaints referred to other regulators, such as complaints about depository institutions with less than $10 billion in assets, are not published in the Consumer Complaint Database.", 
            "title": "Consumer complaints"
        }, 
        {
            "location": "/consumer-complaint-database/#consumer-complaint-database-api", 
            "text": "", 
            "title": "Consumer Complaint Database API"
        }, 
        {
            "location": "/consumer-complaint-database/#a-resource-for-searching-complaints-submitted-to-the-cfpb", 
            "text": "Each week the CFPB sends thousands of consumers\u2019 complaints about financial products and services to companies for response. Those complaints are  published  on our website after the company responds or after 15 days, whichever comes first.  The API allows automation of the same filtering and searching functions offered to website visitors.  Detailed documentation for the search API can be found  here .", 
            "title": "A resource for searching complaints submitted to the CFPB"
        }, 
        {
            "location": "/consumer-complaint-database/#notes", 
            "text": "The database generally updates daily, and contains certain information for each complaint, including the source of the complaint, the date of submission, and the company the complaint was sent to for response. The database also includes information about the actions taken by the company in response to the complaint, such as, whether the company\u2019s response was timely and how the company responded. If the consumer opts to share it and after we take steps to remove personal information, we publish the consumer\u2019s description of what happened. Companies also have the option to select a public response. Company level information should be considered in context of company size and/or market share. Complaints referred to other regulators, such as complaints about depository institutions with less than $10 billion in assets, are not published in the Consumer Complaint Database.", 
            "title": "Notes"
        }, 
        {
            "location": "/hmda/", 
            "text": "HMDA API docs\n\u00b6\n\n\nA resource for data required by the Home Mortgage Disclosure Act\n\u00b6\n\n\nThe CFPB \npublishes data\n\ngleaned from mortgage loan applications going back to 2007.\n\n\nThe API enables automated access to this rich data set.\nFull details on how to use it starts \nhere\n.", 
            "title": "HMDA data"
        }, 
        {
            "location": "/hmda/#hmda-api-docs", 
            "text": "", 
            "title": "HMDA API docs"
        }, 
        {
            "location": "/hmda/#a-resource-for-data-required-by-the-home-mortgage-disclosure-act", 
            "text": "The CFPB  publishes data \ngleaned from mortgage loan applications going back to 2007.  The API enables automated access to this rich data set.\nFull details on how to use it starts  here .", 
            "title": "A resource for data required by the Home Mortgage Disclosure Act"
        }
    ]
}